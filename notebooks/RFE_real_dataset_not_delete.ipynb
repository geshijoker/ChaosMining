{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27f2becc-f3ca-4f4d-b8fe-d133504c8192",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8975b501-9d6f-4289-88f2-b196a9388daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "import warnings\n",
    "from functools import partial\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6b41a85-783f-4ef9-a21e-0c64a8fa1c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import Tensor\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d7d9e5-7545-4be8-8f4c-6f74b4adb275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe7a6199-f38b-4d00-8e86-713f32a84e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92e6101e-cde2-4ed7-a36c-c25cbea54d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chaosmining.data_utils import read_formulas, create_simulation_data\n",
    "from chaosmining.simulation.models import MLPRegressor\n",
    "from chaosmining.simulation.functions import abs_argmax_topk\n",
    "from chaosmining.utils import radar_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f94e9ef-b5ff-4bf1-9f32-50e871879546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, precision_score, recall_score, accuracy_score, roc_curve, auc, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcc8d87a-a388-4423-afda-5c8cfa67df9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients, Saliency, DeepLift, FeatureAblation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e054f29e-9647-4582-b03a-1ea270715390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# mpl.use('Agg')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt \n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "matplotlib.rcParams['lines.linewidth'] = 1\n",
    "matplotlib.rcParams['lines.markersize'] = 5\n",
    "plt.rcParams['figure.figsize'] = [4, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecb3965-1d2a-4ba9-90de-86b1201e0ece",
   "metadata": {},
   "source": [
    "# Santander customer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b70fe02d-9ea8-43cb-b160-e69088e910d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_train_path = '../data/house_prices_advanced_regression/train.csv'\n",
    "house_test_path = '../data/house_prices_advanced_regression/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09d5cdae-c440-4455-862a-d6fd913b5b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_train_path = '../data/santander_customer_satisfaction/train.csv'\n",
    "customer_test_path = '../data/santander_customer_satisfaction/test.csv'\n",
    "sample_path = '../data/santander_customer_satisfaction/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f911d116-6609-48c7-bf94-416b126024ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train  = pd.read_csv(customer_train_path,index_col=0)\n",
    "test   = pd.read_csv(customer_test_path, index_col=0)\n",
    "sample = pd.read_csv(sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d8c2a6f-5b39-4659-a272-7d0c7c16e097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64      259\n",
       "float64    111\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68203886-7eed-460f-a05a-d2934bc88257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc93e9a9-f7c7-458e-87fb-d07c66120e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var3                             208\n",
       "var15                            100\n",
       "ind_var1_0                         2\n",
       "ind_var1                           2\n",
       "ind_var2_0                         1\n",
       "                                ... \n",
       "num_var45_ult3                   172\n",
       "saldo_var2_ult1                    1\n",
       "saldo_medio_var13_medio_hace3      1\n",
       "saldo_medio_var13_medio_ult1       3\n",
       "TARGET                             2\n",
       "Length: 259, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select_dtypes(include=['int64']).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c98b2f9-f170-415b-8cc6-d15eb70f0fed",
   "metadata": {},
   "source": [
    "a good many of the integer features have one single value. Such columns have zero variance and thus have no predictive value, In https://www.kaggle.com/code/carlmcbrideellis/tabular-classification-with-neural-networks-keras/notebook they drop these columns from the train, as well as the test data to maintain consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef8f841a-e7d8-42eb-aa26-e0ad49c8c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_to_drop = train.nunique()\n",
    "# features_to_drop = features_to_drop.loc[features_to_drop.values==1].index\n",
    "# # now drop these columns from both the training and the test datasets\n",
    "# train = train.drop(features_to_drop,axis=1)\n",
    "# test  = test.drop(features_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5702a14b-e2a2-4001-b31a-3017549a6315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64      259\n",
       "float64    111\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d88d137-ac83-4e64-89d9-6db623cae2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020, 370)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88886cbe-5e6d-4f72-b4e0-6191b75b86d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:,:-1]\n",
    "y = train['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cfeeda7-dacc-49f3-86cd-27ac922929ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99183f88-694c-41a7-9ea2-1437fc27b025",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "X_resampled = X_resampled.to_numpy()\n",
    "y_resampled = y_resampled.to_numpy().reshape(y_resampled.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9b1108e-d836-4a4a-9ada-55e10562d51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, \n",
    "                                                  train_size=0.8,\n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=42, \n",
    "                                                  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95905411-3370-42f5-8d11-b6e8391b0cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler  = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test   = scaler.transform(X_test)\n",
    "# test    = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01eb642-7e9f-4884-b33d-5d107495bdfe",
   "metadata": {},
   "source": [
    "# Training and Test a MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "03b69928-b490-4257-8787-aba2ceb8c72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TensorDataset(Tensor(X_train), Tensor(y_train))\n",
    "train_loader = DataLoader(train_set, batch_size=1000, shuffle=True)\n",
    "test_set = TensorDataset(Tensor(X_test), Tensor(y_test))\n",
    "test_loader = DataLoader(test_set, batch_size=y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "069d51e4-28a0-4c9a-a284-efffb8f5ab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_sizes = (100,100,100)\n",
    "num_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c72134c-cf77-4d74-954a-5f47e48c0203",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0dece3f6-ce0f-4a39-a838-39e8a6533e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_channels, out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor)-> Tensor:\n",
    "        out = self.net(x)\n",
    "        return out-x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5911ef9a-9822-4656-b389-b01523fa07ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class LinearBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_channels, out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor)-> Tensor:\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "    \n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, in_channels: int, sizes: List[int], p: float=0.0):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            LinearBlock(in_channels, sizes[0]),\n",
    "            *[LinearBlock(sizes[i], sizes[i+1]) for i in range(len(sizes)-1)]\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(sizes[-1], 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x: Tensor)-> Tensor:\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.project(x)\n",
    "        return x\n",
    "\n",
    "class MLPCReslassifier(nn.Module):\n",
    "    def __init__(self, in_channels: int, sizes: List[int], p: float=0.0):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            LinearBlock(in_channels, sizes[0]),\n",
    "            *[LinearResBlock(sizes[i], sizes[i+1]) for i in range(len(sizes)-1)]\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(sizes[-1], 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x: Tensor)-> Tensor:\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.project(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4c9dfcc9-54e6-42cb-9c81-3b4cbd9e7550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(\n",
       "  (blocks): ModuleList(\n",
       "    (0): LinearBlock(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=369, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1-2): 2 x LinearBlock(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0, inplace=False)\n",
       "  (project): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=0\n",
    "model = MLPClassifier(X_train.shape[-1], hidden_layer_sizes, p=p)\n",
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f46068f1-8b8c-4aa5-88b1-7b2d4c982d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.MSELoss(reduction='mean')\n",
    "criterion = nn.BCELoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8da5584b-ee82-4ae5-b999-2a335843dead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, num_epochs, optimizer):\n",
    "    pbar = trange(num_epochs, desc='Train', unit='epoch', initial=0, disable=False)\n",
    "    for epoch in pbar:  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in dataloader:\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            # forward pass\n",
    "            outputs = model(inputs)\n",
    "            # defining loss\n",
    "            # print(outputs.dtype,targets.dtype)\n",
    "            # print(outputs.shape,targets.shape)\n",
    "            # print(outputs[0],targets[0])\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # computing gradients\n",
    "            loss.backward()\n",
    "            # accumulating running loss\n",
    "            running_loss += loss.item()\n",
    "            # updated weights based on computed gradients\n",
    "            optimizer.step()\n",
    "        pbar.set_postfix(loss = '%.3f' % running_loss)\n",
    "        # print(loss.item())\n",
    "    print('train loss:', running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7cd13aea-b56a-4a19-a0d5-8328781ee487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516929f478714f159f63b6227a3e8558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.6263459026813507\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, num_epochs, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "50e370e3-dfae-4126-8d32-9a2402735602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Drop out0\n",
      "Test auc is 0.7497733729838487\n",
      "Balanced_accuracy_score is 0.722542202372398\n",
      "With Drop out:0\n",
      "Train auc is 0.9339094995732742\n",
      "Balanced_accuracy_score of Train is 0.8581407884234641\n"
     ]
    }
   ],
   "source": [
    "y_pred = model(Tensor(X_test).to(device)).detach().cpu().numpy()\n",
    "\n",
    "y_test =y_test.astype(int)\n",
    "fpr, tpr, thresholds = roc_curve(y_test,y_pred)\n",
    "ACC = balanced_accuracy_score(y_test,np.around(y_pred))\n",
    "print(f'With Drop out{p}')\n",
    "print('Test auc is', auc(fpr, tpr))\n",
    "print('Balanced_accuracy_score is', ACC)\n",
    "\n",
    "y_pred_train = model(Tensor(X_train).to(device)).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_train,y_pred_train)\n",
    "ACC = balanced_accuracy_score(y_train,np.around(y_pred_train))\n",
    "print(f'With Drop out:{p}')\n",
    "print('Train auc is', auc(fpr, tpr))\n",
    "print('Balanced_accuracy_score of Train is', ACC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62584a1-6f28-4cbc-8609-193515f5e27e",
   "metadata": {},
   "source": [
    "# play with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "16e6d1c4-bfee-4bbc-8c4d-7b8677f155a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b84df90b614135abbf1fea74aa8b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.7384424209594727\n",
      "With Drop out0\n",
      "Test auc is 0.7531921244348142\n",
      "Balanced_accuracy_score is 0.7188830051847839\n",
      "With Drop out:0\n",
      "Train auc is 0.9312184490675954\n",
      "Balanced_accuracy_score of Train is 0.8543059572306704\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db77ed297f164f7da2b5c5b34c5ff331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.605219841003418\n",
      "With Drop out0.1\n",
      "Test auc is 0.746643432791271\n",
      "Balanced_accuracy_score is 0.7244685320096842\n",
      "With Drop out:0.1\n",
      "Train auc is 0.936305556419373\n",
      "Balanced_accuracy_score of Train is 0.8558965906852837\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beef475ae40346dda0232a1408bd3546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 3.1344776153564453\n",
      "With Drop out0.2\n",
      "Test auc is 0.7452435964049217\n",
      "Balanced_accuracy_score is 0.720679438849398\n",
      "With Drop out:0.2\n",
      "Train auc is 0.9235104331871754\n",
      "Balanced_accuracy_score of Train is 0.8492930517979497\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1088bb3c8f4808b754914837aa5003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.6422038078308105\n",
      "With Drop out0.3\n",
      "Test auc is 0.7587541594348695\n",
      "Balanced_accuracy_score is 0.7275362879600252\n",
      "With Drop out:0.3\n",
      "Train auc is 0.9337864919682252\n",
      "Balanced_accuracy_score of Train is 0.8537384291652413\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1eba08f4b04a2bb53322104ac26329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.6573023796081543\n",
      "With Drop out0.4\n",
      "Test auc is 0.7607482008025914\n",
      "Balanced_accuracy_score is 0.7190847585040406\n",
      "With Drop out:0.4\n",
      "Train auc is 0.9358712290049168\n",
      "Balanced_accuracy_score of Train is 0.858726456655368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac7d2fcf439b401cb2038a2f7cfc383e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.6352637112140656\n",
      "With Drop out0.5\n",
      "Test auc is 0.7600240998485469\n",
      "Balanced_accuracy_score is 0.7266049061985252\n",
      "With Drop out:0.5\n",
      "Train auc is 0.9351433764205478\n",
      "Balanced_accuracy_score of Train is 0.8580760021146252\n"
     ]
    }
   ],
   "source": [
    "for p in [0,0.1,0.2,0.3,0.4,0.5]:\n",
    "    train_set = TensorDataset(Tensor(X_train), Tensor(y_train))\n",
    "    train_loader = DataLoader(train_set, batch_size=1000, shuffle=True)\n",
    "    test_set = TensorDataset(Tensor(X_test), Tensor(y_test))\n",
    "    test_loader = DataLoader(test_set, batch_size=y_test.shape[0],shuffle=False)\n",
    "    hidden_layer_sizes = (100,100,100)\n",
    "    num_epochs = 500\n",
    "    model = MLPClassifier(X_train.shape[-1], hidden_layer_sizes, p=p)\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    # print(model)\n",
    "    criterion = nn.BCELoss(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), 0.001)\n",
    "    train(model, train_loader, num_epochs, optimizer)\n",
    "    model.eval()\n",
    "    y_pred = model(Tensor(X_test).to(device)).detach().cpu().numpy()\n",
    "    \n",
    "    y_test =y_test.astype(int)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_test,y_pred)\n",
    "    ACC = balanced_accuracy_score(y_test,np.around(y_pred))\n",
    "    print(f'With Drop out{p}')\n",
    "    print('Test auc is', auc(fpr, tpr))\n",
    "    print('Balanced_accuracy_score is', ACC)\n",
    "\n",
    "    y_pred_train = model(Tensor(X_train).to(device)).detach().cpu().numpy()\n",
    "    \n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_train,y_pred_train)\n",
    "    ACC = balanced_accuracy_score(y_train,np.around(y_pred_train))\n",
    "    print(f'With Drop out:{p}')\n",
    "    print('Train auc is', auc(fpr, tpr))\n",
    "    print('Balanced_accuracy_score of Train is', ACC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e65ca51a-29da-4b57-9763-eef3618ea27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4812, 1)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d12e07-6970-46f0-b4df-3ff80cf327e3",
   "metadata": {},
   "source": [
    "# MLP res Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "cfbd5caf-c556-4c8e-ac8d-64afcac1fa05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c655fdeb1d94dcd93426e290b6f3609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.7860514223575592\n",
      "With Drop out0\n",
      "Test auc is 0.7493132095912975\n",
      "Balanced_accuracy_score is 0.7169539118033983\n",
      "With Drop out:0\n",
      "hidden_layer_sizes:(100, 100, 100)\n",
      "Train auc is 0.9318143103454233\n",
      "Balanced_accuracy_score of Train is 0.8528946522789231\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94798cf841847329dda33e9ca6f8d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.5011220872402191\n",
      "With Drop out0\n",
      "Test auc is 0.746303492267044\n",
      "Balanced_accuracy_score is 0.724134118973656\n",
      "With Drop out:0\n",
      "hidden_layer_sizes:(100, 100, 100, 100)\n",
      "Train auc is 0.9433249370277077\n",
      "Balanced_accuracy_score of Train is 0.8617600107804417\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23f1e02ac3a4b3e81087bbdbcf7ceac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.6371416449546814\n",
      "With Drop out0\n",
      "Test auc is 0.7209350851785932\n",
      "Balanced_accuracy_score is 0.7088367953834418\n",
      "With Drop out:0\n",
      "hidden_layer_sizes:(100, 100, 100, 100, 100)\n",
      "Train auc is 0.9334130636840777\n",
      "Balanced_accuracy_score of Train is 0.8579448746255351\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4adb8c8eb80a43478169e7b34dbff80e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.3571505546569824\n",
      "With Drop out0\n",
      "Test auc is 0.727378754546359\n",
      "Balanced_accuracy_score is 0.7130211039499431\n",
      "With Drop out:0\n",
      "hidden_layer_sizes:(100, 100, 100, 100, 100, 100)\n",
      "Train auc is 0.9539942918942826\n",
      "Balanced_accuracy_score of Train is 0.8757284572565849\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe3c0a7421f41fbbeef4ea82cde731c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.5848039388656616\n",
      "With Drop out0.1\n",
      "Test auc is 0.7702582442486485\n",
      "Balanced_accuracy_score is 0.7263423505090816\n",
      "With Drop out:0.1\n",
      "hidden_layer_sizes:(100, 100, 100)\n",
      "Train auc is 0.9326820149751394\n",
      "Balanced_accuracy_score of Train is 0.8511962144064019\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c95be3df019419e94ff3f0a968d7fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.575721800327301\n",
      "With Drop out0.1\n",
      "Test auc is 0.7405065390185392\n",
      "Balanced_accuracy_score is 0.7232663033264424\n",
      "With Drop out:0.1\n",
      "hidden_layer_sizes:(100, 100, 100, 100)\n",
      "Train auc is 0.9347036933378944\n",
      "Balanced_accuracy_score of Train is 0.843859812793482\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8afae1b649c547a5b5814ed6f9d40139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.5571696758270264\n",
      "With Drop out0.1\n",
      "Test auc is 0.7512436848447329\n",
      "Balanced_accuracy_score is 0.7315796455774567\n",
      "With Drop out:0.1\n",
      "hidden_layer_sizes:(100, 100, 100, 100, 100)\n",
      "Train auc is 0.9429071949083143\n",
      "Balanced_accuracy_score of Train is 0.8462900768106478\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8418a7ee6bf24683b3d385c0ad6de34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.4067338705062866\n",
      "With Drop out0.1\n",
      "Test auc is 0.725358457609693\n",
      "Balanced_accuracy_score is 0.711899023845584\n",
      "With Drop out:0.1\n",
      "hidden_layer_sizes:(100, 100, 100, 100, 100, 100)\n",
      "Train auc is 0.9508434313593377\n",
      "Balanced_accuracy_score of Train is 0.8766914409511667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bda86aa6b2e4c1396d71f2edc439fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.6326023638248444\n",
      "With Drop out0.2\n",
      "Test auc is 0.7698961937716263\n",
      "Balanced_accuracy_score is 0.7321213394209403\n",
      "With Drop out:0.2\n",
      "hidden_layer_sizes:(100, 100, 100)\n",
      "Train auc is 0.9330690051932703\n",
      "Balanced_accuracy_score of Train is 0.8533030651698439\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a25ea2d6afd4f9295eb3875aff08c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.5230993330478668\n",
      "With Drop out0.2\n",
      "Test auc is 0.7479645024707872\n",
      "Balanced_accuracy_score is 0.7252783090308101\n",
      "With Drop out:0.2\n",
      "hidden_layer_sizes:(100, 100, 100, 100)\n",
      "Train auc is 0.9377249812551613\n",
      "Balanced_accuracy_score of Train is 0.8548185465062039\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20224c6a5375454b9d19da927d497556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.0401697754859924\n",
      "With Drop out0.2\n",
      "Test auc is 0.7326519782880264\n",
      "Balanced_accuracy_score is 0.6980609571398565\n",
      "With Drop out:0.2\n",
      "hidden_layer_sizes:(100, 100, 100, 100, 100)\n",
      "Train auc is 0.9185585132665084\n",
      "Balanced_accuracy_score of Train is 0.8325190990038457\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bdc3104216747a1857ba7bdd0db4865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.7641938030719757\n",
      "With Drop out0.2\n",
      "Test auc is 0.7278472091712085\n",
      "Balanced_accuracy_score is 0.7188857689288833\n",
      "With Drop out:0.2\n",
      "hidden_layer_sizes:(100, 100, 100, 100, 100, 100)\n",
      "Train auc is 0.936073275906749\n",
      "Balanced_accuracy_score of Train is 0.857734966984897\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab9980f30794de4a1178090c605d034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.5974304676055908\n",
      "With Drop out0.3\n",
      "Test auc is 0.7668671302386769\n",
      "Balanced_accuracy_score is 0.7178935847971964\n",
      "With Drop out:0.3\n",
      "hidden_layer_sizes:(100, 100, 100)\n",
      "Train auc is 0.9346344151783091\n",
      "Balanced_accuracy_score of Train is 0.8495682640378974\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f84977a9c3458a8eaf292c0e9393de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.7970300912857056\n",
      "With Drop out0.3\n",
      "Test auc is 0.7412112937638877\n",
      "Balanced_accuracy_score is 0.7107023226505411\n",
      "With Drop out:0.3\n",
      "hidden_layer_sizes:(100, 100, 100, 100)\n",
      "Train auc is 0.9305991783368404\n",
      "Balanced_accuracy_score of Train is 0.8467897088244136\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6276ab236ad540b4a7aab333a32140b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.4723608493804932\n",
      "With Drop out0.3\n",
      "Test auc is 0.7333525874172259\n",
      "Balanced_accuracy_score is 0.7234072542755121\n",
      "With Drop out:0.3\n",
      "hidden_layer_sizes:(100, 100, 100, 100, 100)\n",
      "Train auc is 0.9474551937888069\n",
      "Balanced_accuracy_score of Train is 0.8683998300007256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a122ae29979842649d4c979f6e592f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.5254745185375214\n",
      "With Drop out0.3\n",
      "Test auc is 0.731782780768763\n",
      "Balanced_accuracy_score is 0.715815249234443\n",
      "With Drop out:0.3\n",
      "hidden_layer_sizes:(100, 100, 100, 100, 100, 100)\n",
      "Train auc is 0.9463068348692008\n",
      "Balanced_accuracy_score of Train is 0.8659042613842503\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04838d782ac1435eb8404b9ea6c19f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.614294558763504\n",
      "With Drop out0.4\n",
      "Test auc is 0.7700634002896405\n",
      "Balanced_accuracy_score is 0.7287993190134539\n",
      "With Drop out:0.4\n",
      "hidden_layer_sizes:(100, 100, 100)\n",
      "Train auc is 0.9339229751255127\n",
      "Balanced_accuracy_score of Train is 0.8548071441158482\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61aa8d1277a24c9984bab53a0a72e374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.5101560354232788\n",
      "With Drop out0.4\n",
      "Test auc is 0.7495011441900572\n",
      "Balanced_accuracy_score is 0.7299324540942105\n",
      "With Drop out:0.4\n",
      "hidden_layer_sizes:(100, 100, 100, 100)\n",
      "Train auc is 0.9422798906752633\n",
      "Balanced_accuracy_score of Train is 0.8641052751604109\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d66fcbfba03249fabf9289c512f5bcda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.05475315451622\n",
      "With Drop out0.4\n",
      "Test auc is 0.7219272693102801\n",
      "Balanced_accuracy_score is 0.6939789071050333\n",
      "With Drop out:0.4\n",
      "hidden_layer_sizes:(100, 100, 100, 100, 100)\n",
      "Train auc is 0.9179794100472335\n",
      "Balanced_accuracy_score of Train is 0.8250702283587814\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dbdbb13824a4159ab2eb510813f4d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.519183337688446\n",
      "With Drop out0.4\n",
      "Test auc is 0.7360113092408548\n",
      "Balanced_accuracy_score is 0.7264694827376543\n",
      "With Drop out:0.4\n",
      "hidden_layer_sizes:(100, 100, 100, 100, 100, 100)\n",
      "Train auc is 0.9499744310034448\n",
      "Balanced_accuracy_score of Train is 0.8745908096733734\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44810737ff1c44a383414e72fffbe4da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.6326513886451721\n",
      "With Drop out0.5\n",
      "Test auc is 0.7530967752633848\n",
      "Balanced_accuracy_score is 0.7177553975922262\n",
      "With Drop out:0.5\n",
      "hidden_layer_sizes:(100, 100, 100)\n",
      "Train auc is 0.9335287288407916\n",
      "Balanced_accuracy_score of Train is 0.8556001285360367\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea850fd72d2046ffa41fe8e892770425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.524756371974945\n",
      "With Drop out0.5\n",
      "Test auc is 0.7503413223962767\n",
      "Balanced_accuracy_score is 0.7220751296195983\n",
      "With Drop out:0.5\n",
      "hidden_layer_sizes:(100, 100, 100, 100)\n",
      "Train auc is 0.9409288801816091\n",
      "Balanced_accuracy_score of Train is 0.8638399104394066\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874d876d010743c28376223ac5625ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.4353521764278412\n",
      "With Drop out0.5\n",
      "Test auc is 0.7376377726433554\n",
      "Balanced_accuracy_score is 0.726201399560012\n",
      "With Drop out:0.5\n",
      "hidden_layer_sizes:(100, 100, 100, 100, 100)\n",
      "Train auc is 0.9477549384443685\n",
      "Balanced_accuracy_score of Train is 0.8724253920867411\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788351affb3648acbb0c29a4215c76e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.489148736000061\n",
      "With Drop out0.5\n",
      "Test auc is 0.7483956465502946\n",
      "Balanced_accuracy_score is 0.7210829454879114\n",
      "With Drop out:0.5\n",
      "hidden_layer_sizes:(100, 100, 100, 100, 100, 100)\n",
      "Train auc is 0.9477419811826007\n",
      "Balanced_accuracy_score of Train is 0.8745923645447855\n"
     ]
    }
   ],
   "source": [
    "for p in [0,0.1,0.2,0.3,0.4,0.5]:\n",
    "    for hidden_layer_sizes in [(100,100,100),(100,100,100,100),(100,100,100,100,100),(100,100,100,100,100,100)]:\n",
    "        train_set = TensorDataset(Tensor(X_train), Tensor(y_train))\n",
    "        train_loader = DataLoader(train_set, batch_size=1000, shuffle=True)\n",
    "        test_set = TensorDataset(Tensor(X_test), Tensor(y_test))\n",
    "        test_loader = DataLoader(test_set, batch_size=y_test.shape[0],shuffle=False)\n",
    "        num_epochs = 500\n",
    "        # model = MLPClassifier(X_train.shape[-1], hidden_layer_sizes, p=p)\n",
    "        model = MLPCReslassifier(X_train.shape[-1], hidden_layer_sizes)\n",
    "        model.to(device)\n",
    "        model.train()\n",
    "        \n",
    "        criterion = nn.BCELoss(reduction='mean')\n",
    "        optimizer = torch.optim.Adam(model.parameters(), 0.001)\n",
    "        train(model, train_loader, num_epochs, optimizer)\n",
    "        model.eval()\n",
    "        y_pred = model(Tensor(X_test).to(device)).detach().cpu().numpy()\n",
    "        \n",
    "        y_test = y_test.astype(int)\n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(y_test,y_pred)\n",
    "        ACC = balanced_accuracy_score(y_test,np.around(y_pred))\n",
    "        print(f'With Drop out{p}')\n",
    "        print('Test auc is', auc(fpr, tpr))\n",
    "        print('Balanced_accuracy_score is', ACC)\n",
    "        \n",
    "        y_pred_train = model(Tensor(X_train).to(device)).detach().cpu().numpy()\n",
    "        fpr, tpr, thresholds = roc_curve(y_train,y_pred_train)\n",
    "        ACC = balanced_accuracy_score(y_train,np.around(y_pred_train))\n",
    "        print(f'With Drop out:{p}')\n",
    "        print(f'hidden_layer_sizes:{hidden_layer_sizes}')\n",
    "        print('Train auc is', auc(fpr, tpr))\n",
    "        print('Balanced_accuracy_score of Train is', ACC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d687d80-5386-4ce7-874d-c4f72b1ee50f",
   "metadata": {},
   "source": [
    "# Iterative Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8456b7ff-6f7b-41e4-a8a7-2cf0386e5481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89374cb2-a981-4e1d-86f2-bf9d67781fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe01570d-aba7-4745-8bb5-2b74a748aff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saliency\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9a0bc8cf694979bf7aec0e75448cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.38475772738456726\n",
      "With 369,Saliency get ACC:0.7141597665188986 AUC:0.7606487060150127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f64770d591741e995691ee28c74ceb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.366638720035553\n",
      "With 185,Saliency get ACC:0.727928739622141 AUC:0.7818134583282664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4dd80dbc7474eedb3be0374291c5577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.45297640562057495\n",
      "With 93,Saliency get ACC:0.7289927811004124 AUC:0.7698105177045448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee540da43ebc4c5593d7792f529a4e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6256109476089478\n",
      "With 47,Saliency get ACC:0.6242828084062041 AUC:0.7095194401759952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1425d0c70884af690c060417a0f2d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6463103890419006\n",
      "With 24,Saliency get ACC:0.5838105398144975 AUC:0.7063148788927336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1c213fbc8b4c3b93df59b2f5eae110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6697629690170288\n",
      "With 12,Saliency get ACC:0.49707043125462924 AUC:0.701052710127464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d778ec9c893c40e3b9dd2a0717fdd600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.668323814868927\n",
      "With 6,Saliency get ACC:0.5672363664503577 AUC:0.7068012978542291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d112130f63db4da9b41e31aa6e6aa3aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6749904155731201\n",
      "With 3,Saliency get ACC:0.5580496810639309 AUC:0.7031697381076092\n",
      "Deep Lift\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2290c79eaecc41b7a325198bd4446b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.37862691283226013\n",
      "With 369,Deep Lift get ACC:0.7243358722929126 AUC:0.7681260156759565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5bf4dfc53fc4685807a0efe37d97d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3872824013233185\n",
      "With 185,Deep Lift get ACC:0.7236725737090551 AUC:0.7841543495804636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c9beade66843fa81338b540c4c4d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3992447555065155\n",
      "With 93,Deep Lift get ACC:0.7216080568667986 AUC:0.7764752866002631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81371ee9fef6484aaab26b37729db33b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.43131592869758606\n",
      "With 47,Deep Lift get ACC:0.7249383685065833 AUC:0.8019404247321932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b9ed03be174bb3933fb94577cf7959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.48790064454078674\n",
      "With 24,Deep Lift get ACC:0.7096355174281703 AUC:0.7935068596128547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca885559b0014a359dc2549a47085c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5080883502960205\n",
      "With 12,Deep Lift get ACC:0.7063107332765844 AUC:0.7848425218612161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a072ff1bc094434acfc729e75a52b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5389315485954285\n",
      "With 6,Deep Lift get ACC:0.6761555214079618 AUC:0.7558895386758351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce18a1ed7b54883bff804c7291896ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5489560961723328\n",
      "With 3,Deep Lift get ACC:0.6811496069955891 AUC:0.7570475474534862\n",
      "Feature Ablation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc7847358764e5a8815b0599b094d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.37151235342025757\n",
      "With 369,Feature Ablation get ACC:0.720679438849398 AUC:0.7778626861381651\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725c7c3d9dce4857aafd1fee75b0128b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.37967848777770996\n",
      "With 185,Feature Ablation get ACC:0.7132256210132992 AUC:0.7650444410051185\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59664067e8154e4cb6b7609390ea77e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3976901173591614\n",
      "With 93,Feature Ablation get ACC:0.7282631526581691 AUC:0.7916731154028986\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9e1b785b104d21b468027f524bb785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4430498480796814\n",
      "With 47,Feature Ablation get ACC:0.7233381606730269 AUC:0.8006138275644783\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2317e9e84a941c193c7238625ccbe26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4823334217071533\n",
      "With 24,Feature Ablation get ACC:0.7076318029561006 AUC:0.7965483599942514\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79827e35c8fb4222998a1837c9bfaf0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.505646288394928\n",
      "With 12,Feature Ablation get ACC:0.7076373304442996 AUC:0.7901627292525731\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac8421518494c3895582485489e3b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5299996137619019\n",
      "With 6,Feature Ablation get ACC:0.6984617000342704 AUC:0.7771814232176615\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4cee8f15754cf68625eea978b367a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5914753079414368\n",
      "With 3,Feature Ablation get ACC:0.6664907082923378 AUC:0.6814536188465237\n",
      "Integrated Gradients\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1dbb2b7028041909a386a4440721301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3932625353336334\n",
      "With 369,Integrated Gradients get ACC:0.7140188155698288 AUC:0.7671891064262579\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959b23e7dd1c495691e978194567856e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3778427839279175\n",
      "With 185,Integrated Gradients get ACC:0.7240042230009839 AUC:0.7807646174425418\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf88536760b433c8219a380d10adb3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3814714550971985\n",
      "With 93,Integrated Gradients get ACC:0.7190792310158418 AUC:0.7770294172921941\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed50276d5daf461294940b686de4c48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4367649555206299\n",
      "With 47,Integrated Gradients get ACC:0.7144886520667278 AUC:0.7922507379196745\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496b9f18157242c28a32fa19e3146cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4702688455581665\n",
      "With 24,Integrated Gradients get ACC:0.7062388759299999 AUC:0.794837602396719\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b224d43c8c143818e53d6637f47642f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5034200549125671\n",
      "With 12,Integrated Gradients get ACC:0.7069049382579569 AUC:0.7885860132438616\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a53475a16234f03a8db18e330128ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5498339533805847\n",
      "With 6,Integrated Gradients get ACC:0.6839437522800889 AUC:0.762048542401362\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23dd07b6a9ad4a4c81f112e36b848414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5544193983078003\n",
      "With 3,Integrated Gradients get ACC:0.6878710326453453 AUC:0.7646934455044938\n",
      "Saliency\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f74a056fe647b893fc94de37a6d2f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3885156512260437\n",
      "With 369,Saliency get ACC:0.7194108803077706 AUC:0.7814417347468964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c293001456c149b88e6cabf123d5f1c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3536995053291321\n",
      "With 185,Saliency get ACC:0.716019766297799 AUC:0.7616878737963895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e6f815417d43bcbed0597f909fae1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.45000842213630676\n",
      "With 93,Saliency get ACC:0.7206739113611993 AUC:0.7661015731231414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3796605c2e41b080dd780786d479a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6323398947715759\n",
      "With 47,Saliency get ACC:0.628342748488232 AUC:0.716772886564887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141f33f284234bafb104c153f598f4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.646482527256012\n",
      "With 24,Saliency get ACC:0.5876714903213681 AUC:0.7076387123163492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99eb0655beb945dfa807f3fb35cd3c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6547289490699768\n",
      "With 12,Saliency get ACC:0.5802812385995556 AUC:0.7059486827995622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb5d4d867934204ac49ef875c0cbcce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6672528982162476\n",
      "With 6,Saliency get ACC:0.5758233193672132 AUC:0.704548846413213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ed85669a4642efb3de4d12d37dbf77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6726519465446472\n",
      "With 3,Saliency get ACC:0.563239992482616 AUC:0.7033203621610269\n",
      "Deep Lift\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3921b41e56b04b42987f57ffc4e22dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.38236168026924133\n",
      "With 369,Deep Lift get ACC:0.7197452933437987 AUC:0.7712379915318881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61a9a050a494d81a33af0d50f608a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3808014392852783\n",
      "With 185,Deep Lift get ACC:0.7258697502680831 AUC:0.7802132504947101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d95e1d78f0647dcbd8434bab27e8623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.39117830991744995\n",
      "With 93,Deep Lift get ACC:0.7285948019500978 AUC:0.7824809025282731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8953c69d55740108348ed0fea91bd54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4266969561576843\n",
      "With 47,Deep Lift get ACC:0.7436433885713654 AUC:0.8034784483235129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4644f4b1014ba4930c142abb241a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.47891390323638916\n",
      "With 24,Deep Lift get ACC:0.711899023845584 AUC:0.7934999502526061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe71ad4ffabb44cbaf685651700aae3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5031755566596985\n",
      "With 12,Deep Lift get ACC:0.7135572703052279 AUC:0.7907859535469893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f60d845a254515966658668f3e9d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5332711338996887\n",
      "With 6,Deep Lift get ACC:0.6939982533137292 AUC:0.7721210077716484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea41f9c3b41480d843033bdf3891d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5895321369171143\n",
      "With 3,Deep Lift get ACC:0.664227201874924 AUC:0.6844356987297832\n",
      "Feature Ablation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d5f945b7834d9fb4065032ed56f554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.38954415917396545\n",
      "With 369,Feature Ablation get ACC:0.7259360801264689 AUC:0.7857904860873122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47cf1c75bfd24d1d987638a535c4d1b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.37701961398124695\n",
      "With 185,Feature Ablation get ACC:0.7165531689089844 AUC:0.7690960898548481\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6844fcb3f4f84239ba5d3bc65f5be296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3819845914840698\n",
      "With 93,Feature Ablation get ACC:0.7288048465016528 AUC:0.7848383762450667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c104b481e94c5586833d629ef54418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.430105984210968\n",
      "With 47,Feature Ablation get ACC:0.7213482649214544 AUC:0.7989403805122874\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98b4a1a907b419ca539a83fe4429495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.48053452372550964\n",
      "With 24,Feature Ablation get ACC:0.7208176260543684 AUC:0.8024558630067324\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc0f00e87564843ab1ec87fe75b0dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5097689032554626\n",
      "With 12,Feature Ablation get ACC:0.7134301380766552 AUC:0.7894068452413854\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4bfd768d85442a0aec9098653a5723b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5245277285575867\n",
      "With 6,Feature Ablation get ACC:0.7000480891473297 AUC:0.7874570237792543\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29bb713d86c74bab9c628cbc9c4ea0f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5922537446022034\n",
      "With 3,Feature Ablation get ACC:0.6654266668140664 AUC:0.6755364427296947\n",
      "Integrated Gradients\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e99b30a5d0c422c908a9a7d5c6186c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3986503481864929\n",
      "With 369,Integrated Gradients get ACC:0.7162132283847574 AUC:0.7704337419989609\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ede21f8f0642cea7609a56f280db4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3855324983596802\n",
      "With 185,Integrated Gradients get ACC:0.7182114153686282 AUC:0.774073592977879\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90af58e0b35348f5abeb4ab84f35905c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.38489460945129395\n",
      "With 93,Integrated Gradients get ACC:0.7162187558729562 AUC:0.7744245884785035\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1499d0b29a6c422fad4e376c272b793a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4325428605079651\n",
      "With 47,Integrated Gradients get ACC:0.7220723658754988 AUC:0.7914865626761884\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e022806d03489c856823382ce44480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4788835644721985\n",
      "With 24,Integrated Gradients get ACC:0.7127557845164001 AUC:0.7933451805830395\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db454c1b3b904ec98242e6c2ca76182b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5046855807304382\n",
      "With 12,Integrated Gradients get ACC:0.702709574715058 AUC:0.7918790143383043\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a23cd7a076449399ff32818e8bfefd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5832284092903137\n",
      "With 6,Integrated Gradients get ACC:0.6663580485755662 AUC:0.6931677482118576\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba087fad1e12401fb5b5934bb69023fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5879533290863037\n",
      "With 3,Integrated Gradients get ACC:0.6718800092861801 AUC:0.6909083874105929\n",
      "Saliency\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a877f0d377df4115b8ddb4938534b709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3783801198005676\n",
      "With 369,Saliency get ACC:0.7283322462606543 AUC:0.7783408138673624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a660d1ac08b944b5a0bbb6b825fc5c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3695530891418457\n",
      "With 185,Saliency get ACC:0.7316625579004389 AUC:0.7749234442884464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d60e299ed824b068cea63c2d4f73600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4402537941932678\n",
      "With 93,Saliency get ACC:0.7194799739102558 AUC:0.7655432968150613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c465c3277bf4275a0acc9957bef8f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6306423544883728\n",
      "With 47,Saliency get ACC:0.6321373691367169 AUC:0.7148382656953027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc732d4e8d64616a907f6f7f0c94833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6483128070831299\n",
      "With 24,Saliency get ACC:0.5863393656654543 AUC:0.7111942691002355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87818a5536cc419faa85125864cfed71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6596464514732361\n",
      "With 12,Saliency get ACC:0.5828100644505124 AUC:0.7139082658058524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca2251ef2f94d568a6f05bf69068a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6696717739105225\n",
      "With 6,Saliency get ACC:0.5606448367732735 AUC:0.7072282963175873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb77a4370d9447858fc66e2b30451c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6770987510681152\n",
      "With 3,Saliency get ACC:0.5600451043037022 AUC:0.7070237792542313\n",
      "Deep Lift\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6cbf8f87904ac8ae000412b28061e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3823089599609375\n",
      "With 369,Deep Lift get ACC:0.7270747426954243 AUC:0.7756516908586399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea7bdc3a738c49f396dd3ebcc40ac8bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.37347736954689026\n",
      "With 185,Deep Lift get ACC:0.725875277756282 AUC:0.7844846170003428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab3611107e44927978f467a678cfeb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3892381489276886\n",
      "With 93,Deep Lift get ACC:0.729534474943896 AUC:0.7818839338028015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc27ba20397d49d3a5d6ef5cc4188b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.44103699922561646\n",
      "With 47,Deep Lift get ACC:0.7203505533015687 AUC:0.7956225057209505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b9c79ef2604850bf0f4579f137a24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4743030369281769\n",
      "With 24,Deep Lift get ACC:0.709096587328786 AUC:0.799088240821606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d889efad95b149a8b859b110ee88eece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5026014447212219\n",
      "With 12,Deep Lift get ACC:0.7047740915573145 AUC:0.7896652553146799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7410fbbdbb4bfe90cad7c8152a75eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5470403432846069\n",
      "With 6,Deep Lift get ACC:0.6884680013708171 AUC:0.7632120786672121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660ad63900d443ebaa473a150b8b854b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5922619104385376\n",
      "With 3,Deep Lift get ACC:0.6665570381507235 AUC:0.6763158185657273\n",
      "Feature Ablation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a555b4d7e0224146bc96278c5d64ebdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3797397315502167\n",
      "With 369,Feature Ablation get ACC:0.7218706125562422 AUC:0.7675497750312302\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354add4356ce413088851e372f01fe71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.38041365146636963\n",
      "With 185,Feature Ablation get ACC:0.7240733166034691 AUC:0.7800598626971932\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0231c51bf44c4e3e810d6e5bc1ab6fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3945050835609436\n",
      "With 93,Feature Ablation get ACC:0.7166194987673702 AUC:0.7775724930077275\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4e402a29fa4f599f09c2a94a95d29f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4206664264202118\n",
      "With 47,Feature Ablation get ACC:0.7322650541141095 AUC:0.7991752987607371\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1d7e349da94ca2b8b4c2a859f7f7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.47258052229881287\n",
      "With 24,Feature Ablation get ACC:0.7142260963772842 AUC:0.7948693854538621\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446f6d96ef6046a0b9fc501949bc6a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5062080025672913\n",
      "With 12,Feature Ablation get ACC:0.7100998264368705 AUC:0.7898656267618869\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6377421703d427d98f40e0e1d23555a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5433619618415833\n",
      "With 6,Feature Ablation get ACC:0.6910051184540722 AUC:0.7602908011541394\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ff60952c9b40cd90272233285ed63b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.59214186668396\n",
      "With 3,Feature Ablation get ACC:0.6648269343444952 AUC:0.6756773936787644\n",
      "Integrated Gradients\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de2b083f14d4af4867ad3844ce0b17b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3844602704048157\n",
      "With 369,Integrated Gradients get ACC:0.7268702256320683 AUC:0.7783725969245056\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad7badeb37e4afa9360606098174dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.37673982977867126\n",
      "With 185,Integrated Gradients get ACC:0.7152155167648717 AUC:0.7682282742076345\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b46e9c154e411c918bc5744cb5048c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.39494726061820984\n",
      "With 93,Integrated Gradients get ACC:0.7204085919276562 AUC:0.7876228484252187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08ac3a70f3b46c2a014f347ff7844dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4346763789653778\n",
      "With 47,Integrated Gradients get ACC:0.7242723061786263 AUC:0.7950089545308822\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6649fd308d4935b2385c5bc85b5c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.47996455430984497\n",
      "With 24,Integrated Gradients get ACC:0.7182141791127277 AUC:0.7943829664923665\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e1622fd7744d0c8e291c80ebd2d17a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5013460516929626\n",
      "With 12,Integrated Gradients get ACC:0.7118934963573853 AUC:0.7909531600650033\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ecf5aff1ec433f955ccc3bff8cd19e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5310701131820679\n",
      "With 6,Integrated Gradients get ACC:0.6963336170777275 AUC:0.7754637562598804\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a9bcfe5ba846299fad7819d26672e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5922533869743347\n",
      "With 3,Integrated Gradients get ACC:0.6648269343444952 AUC:0.6762743624042362\n",
      "Saliency\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5589a4b5e4844789ccffe6760b0c38c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3818289041519165\n",
      "With 369,Saliency get ACC:0.7153509402257426 AUC:0.7732486153642063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b866b4d3d9dd422f9915af74c26fee20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3589174151420593\n",
      "With 185,Saliency get ACC:0.7270609239749273 AUC:0.7681591806051494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb160a9c6c4d4879b351af57f4ffc455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4635331630706787\n",
      "With 93,Saliency get ACC:0.7198751893164708 AUC:0.7685668328598118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2045d0c619d74779ad62db2f83e4c38d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6270796656608582\n",
      "With 47,Saliency get ACC:0.5866046850989973 AUC:0.7042420708181788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce7061fed45541ca93c8a9f7e24571ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6463607549667358\n",
      "With 24,Saliency get ACC:0.5914661109698531 AUC:0.7059597377759599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6617a9999a604ffdad45e2e36e913694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6555216312408447\n",
      "With 12,Saliency get ACC:0.588003139613297 AUC:0.7025548050454912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eafae66212b44f9bed954c1d4718ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6650215983390808\n",
      "With 6,Saliency get ACC:0.5621759510043446 AUC:0.6960047315298981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8937b1c1e44de0bd0eeed5ad0a557a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6709430813789368\n",
      "With 3,Saliency get ACC:0.5631100965099439 AUC:0.6975551919696652\n",
      "Deep Lift\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707c6de5056f42e280462bf693394f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.38697683811187744\n",
      "With 369,Deep Lift get ACC:0.7245376256121693 AUC:0.7784624186077362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232cefe04e2e4d63a8e395c25e4c3213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3810286819934845\n",
      "With 185,Deep Lift get ACC:0.7253391114009972 AUC:0.7778419580574196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b74860851de49dba7958249253f5ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.38694506883621216\n",
      "With 93,Deep Lift get ACC:0.7277380412792819 AUC:0.7844417789668019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b26a360307d431e9ee3749cd2cae632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4385359287261963\n",
      "With 47,Deep Lift get ACC:0.73412505389301 AUC:0.7938661463457776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a400b895b4a4c76aabc7d95323f9b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4646686315536499\n",
      "With 24,Deep Lift get ACC:0.721610820610898 AUC:0.8047787899222836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e748756be84e1486527db3bd11de7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4961267411708832\n",
      "With 12,Deep Lift get ACC:0.7116254131797428 AUC:0.7880567562488254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2149bcbaad34f64a3727227a0e44818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.523138165473938\n",
      "With 6,Deep Lift get ACC:0.6996528737411145 AUC:0.7871986137059597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774ba52e7d3042eb816fe8c7ddae79ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5921611785888672\n",
      "With 3,Deep Lift get ACC:0.6665570381507235 AUC:0.675079043081243\n",
      "Feature Ablation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0977934dca49d3b6f5cb847005e5c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.39343759417533875\n",
      "With 369,Feature Ablation get ACC:0.7345257967874239 AUC:0.7915667112550715\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1c058769704181b36c0c41965fd3a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3778386414051056\n",
      "With 185,Feature Ablation get ACC:0.7206766751052986 AUC:0.7765402345865993\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249e92209df745bba6d5913c03ffeeb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.38295838236808777\n",
      "With 93,Feature Ablation get ACC:0.7349928695402235 AUC:0.7934930408923577\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec82d2420426411793fe27749460ccfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.42398056387901306\n",
      "With 47,Feature Ablation get ACC:0.7188194390704976 AUC:0.7924151806935893\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0b7d40a5974e73bdd9ee986bd36b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4787522852420807\n",
      "With 24,Feature Ablation get ACC:0.7094973302231999 AUC:0.7967349127209613\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f179912410e242dab3a878b3dfd221c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5022626519203186\n",
      "With 12,Feature Ablation get ACC:0.7081652055672861 AUC:0.7886343787656014\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db19df10acc42d6adefc9eb9f4fd7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5360094308853149\n",
      "With 6,Feature Ablation get ACC:0.6876748068142875 AUC:0.7691845296660291\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a61c9f4ade944a1b9c0244ad0a9302bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5877295136451721\n",
      "With 3,Feature Ablation get ACC:0.6700172457631803 AUC:0.6907287440441315\n",
      "Integrated Gradients\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79ceb826de84b2280817762db850560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3874373435974121\n",
      "With 369,Integrated Gradients get ACC:0.7289319787302254 AUC:0.780745271233846\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c4cdd6de364e6e989edd74374ceb19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.38952550292015076\n",
      "With 185,Integrated Gradients get ACC:0.7136263639077131 AUC:0.7777134439567972\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b371241104bc4e8da18fb138faff1dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.40499240159988403\n",
      "With 93,Integrated Gradients get ACC:0.7274644306134406 AUC:0.7919439623246404\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01076ba74ed94270a6ff531cf90cd868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.44013169407844543\n",
      "With 47,Integrated Gradients get ACC:0.7270084128370387 AUC:0.8001191173706843\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c55abe151247bcbf9304dd0e9cae1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.46928536891937256\n",
      "With 24,Integrated Gradients get ACC:0.7144223222083421 AUC:0.7965898161557425\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e701b181fa274af180b49bb4e8cce2f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.509171187877655\n",
      "With 12,Integrated Gradients get ACC:0.7096963197983572 AUC:0.7884492079109412\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044d5cfa061847a1b43f95a504f0021a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5355674028396606\n",
      "With 6,Integrated Gradients get ACC:0.6875449108416154 AUC:0.7696377836983318\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67eeee279dbe4e4eb4563b88ec512ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5393649935722351\n",
      "With 3,Integrated Gradients get ACC:0.6892031573012591 AUC:0.7692840244536079\n",
      "Saliency\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b8b99d887047a481b06e7f46ff9fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.37372779846191406\n",
      "With 369,Saliency get ACC:0.7180124257934709 AUC:0.7648164321169175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e61b4959f0481f9548fbf0d7c4cdf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.35017892718315125\n",
      "With 185,Saliency get ACC:0.7274644306134406 AUC:0.7803431464673823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268a6cfb560c4dc481759a84464fe82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.46067023277282715\n",
      "With 93,Saliency get ACC:0.7327183081464121 AUC:0.7799216754922229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a06cb1a38d04444c8ca3e14b4ed27d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6284144520759583\n",
      "With 47,Saliency get ACC:0.5975878041500382 AUC:0.7157406281437589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b74bc27e7744ec2a385fe7dcea8457c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6426669359207153\n",
      "With 24,Saliency get ACC:0.5896005837027538 AUC:0.7096714461014626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eaf292eba6c45fa97d55a9d89b19337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6604412794113159\n",
      "With 12,Saliency get ACC:0.5760223089423704 AUC:0.6892377041025017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630d2bf11a054b419f591c0bd050512c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6742001175880432\n",
      "With 6,Saliency get ACC:0.5617779718540301 AUC:0.6918563516366892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2ccb23559c468ba924408d942f6e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.683847963809967\n",
      "With 3,Saliency get ACC:0.5507920890588899 AUC:0.6953262323534939\n",
      "Deep Lift\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7237374d993e4a199a111e6f8e8dca6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.38988780975341797\n",
      "With 369,Deep Lift get ACC:0.7256044308345402 AUC:0.7777756281990338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82809434d04d4c40a09b11f3d1de0b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.38448482751846313\n",
      "With 185,Deep Lift get ACC:0.7274727218457389 AUC:0.7861774102612291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2ffb43f66b4d468da91878b9535a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3997839391231537\n",
      "With 93,Deep Lift get ACC:0.7224703450258134 AUC:0.7881341410836087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ea4888cf4b4cbfa36fe520d7c2e9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.43495941162109375\n",
      "With 47,Deep Lift get ACC:0.7327956929811954 AUC:0.8065462042738539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c28a8426d445ac9dd63c5845bc07af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4744735062122345\n",
      "With 24,Deep Lift get ACC:0.7279370308544391 AUC:0.8006856849110628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ea6622eb014b0e8260f8cdc8adf128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5027377009391785\n",
      "With 12,Deep Lift get ACC:0.709831743259228 AUC:0.7867757608587507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3bda31b88e49cdad87985a3b6e8638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5300319790840149\n",
      "With 6,Deep Lift get ACC:0.6892722509037443 AUC:0.7716953911803398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53572ae98a414aacb4d268efdfe8c74a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5924282073974609\n",
      "With 3,Deep Lift get ACC:0.6648269343444952 AUC:0.6761817769769062\n",
      "Feature Ablation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/ChaosMining/src/captum/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/zwkan/ChaosMining/src/captum/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b98222ae6c441bab529d7aedd46272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3893316686153412\n",
      "With 369,Feature Ablation get ACC:0.7148175376145571 AUC:0.7755687785356579\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d541203c6a74e9ba0482b2d48f2d50c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.39413419365882874\n",
      "With 185,Feature Ablation get ACC:0.7138806283648584 AUC:0.770451706335607\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b459de8f1b41509b192f92901ad907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.37091678380966187\n",
      "With 93,Feature Ablation get ACC:0.7205467791326265 AUC:0.7781888079418949\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f43b9403f4644ffb9e6565d8364d114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.42423924803733826\n",
      "With 47,Feature Ablation get ACC:0.723542677736383 AUC:0.7950365919718761\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6597df2a851460189d309ea90a12484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.47650599479675293\n",
      "With 24,Feature Ablation get ACC:0.7037736161933295 AUC:0.7911880783134528\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c5fbcb9701a4cc580181feb849d95fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5035417675971985\n",
      "With 12,Feature Ablation get ACC:0.7089003614977283 AUC:0.790400411245122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff4dbe1742e49c0a5ce00cffafc22cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.522627055644989\n",
      "With 6,Feature Ablation get ACC:0.7071066915772135 AUC:0.7876891782836044\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce0615dc4ff24526aed6d577d1cf066c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5913752913475037\n",
      "With 3,Feature Ablation get ACC:0.664893264202881 AUC:0.681536531169506\n",
      "Integrated Gradients\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0fa1acb8cbb4c8abb905acfc9ec4b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.39954501390457153\n",
      "With 369,Integrated Gradients get ACC:0.7190156649015554 AUC:0.7868876924947764\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4b2c9ed8264ca59d07f5bbf6a0f666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.39022308588027954\n",
      "With 185,Integrated Gradients get ACC:0.7226030047425849 AUC:0.78403136296804\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ba070d1dc848c48913915fa1cc2f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3915769159793854\n",
      "With 93,Integrated Gradients get ACC:0.7175564080170689 AUC:0.7712172634511425\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7964b8596e240d1b9d93a38466beb0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4469735026359558\n",
      "With 47,Integrated Gradients get ACC:0.7179488596791845 AUC:0.798691643543341\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603a7242ddea4a92a5913a1ba0d4e0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.47558239102363586\n",
      "With 24,Integrated Gradients get ACC:0.7119542987275722 AUC:0.7959983749184696\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3605914e63754549829e22147b4f3a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.496622234582901\n",
      "With 12,Integrated Gradients get ACC:0.7074991432393292 AUC:0.7895450324463558\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667936219235409e9baed79dd8cf348b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5303881764411926\n",
      "With 6,Integrated Gradients get ACC:0.6946007495273998 AUC:0.7747120178648419\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37f4e4982ac48a39bc692c85336fbe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5376461744308472\n",
      "With 3,Integrated Gradients get ACC:0.6926633649137159 AUC:0.7713029395182242\n"
     ]
    }
   ],
   "source": [
    "for repeat in range(1,6):\n",
    "    for xai_method in [Saliency,DeepLift,FeatureAblation,IntegratedGradients]:\n",
    "        print(xai_method.get_name())\n",
    "        num_epochs = 500\n",
    "        hidden_layer_sizes = (100,100,100)\n",
    "        reduce_rate = 0.5\n",
    "        best_score = 0\n",
    "        num_cur_features = X_train.shape[-1]\n",
    "        select_arr = np.ones(num_cur_features)\n",
    "        remaining_inds = np.nonzero(select_arr)[0]\n",
    "        num_select = 3\n",
    "        num_list = []\n",
    "        auc_list = []\n",
    "        acc_list = []\n",
    "        feature_list = []\n",
    "        resuming = True\n",
    "        start_time = time.time()\n",
    "        while resuming:\n",
    "            num_list.append(num_cur_features)\n",
    "            bool_arr = np.array(select_arr, dtype='bool') \n",
    "            # print(X_train[...,bool_arr].shape)\n",
    "            # torch.manual_seed(42)\n",
    "            train_set = TensorDataset(Tensor(X_train[...,bool_arr]), Tensor(y_train))\n",
    "            train_loader = DataLoader(train_set, batch_size=y_train.shape[0], shuffle=True)\n",
    "            test_set = TensorDataset(Tensor(X_test[...,bool_arr]), Tensor(y_test))\n",
    "            test_loader = DataLoader(test_set, batch_size=y_test.shape[0])\n",
    "        \n",
    "            model = MLPClassifier(int(np.sum(select_arr)), hidden_layer_sizes, p=0.0)\n",
    "            model.to(device)\n",
    "            model.train()\n",
    "        \n",
    "            # criterion = nn.MSELoss(reduction='mean')\n",
    "            criterion = nn.BCELoss(reduction='mean')\n",
    "            optimizer = torch.optim.Adam(model.parameters(), 0.001)\n",
    "\n",
    "            train(model, train_loader, num_epochs, optimizer)\n",
    "        \n",
    "            model.eval()\n",
    "            y_pred = model(Tensor(X_test[...,bool_arr]).to(device)).detach().cpu().numpy()\n",
    "            fpr, tpr, thresholds = roc_curve(y_test,y_pred)\n",
    "            auc_score = auc(fpr, tpr)\n",
    "            # print('Test auc is', auc_score)\n",
    "            acc = balanced_accuracy_score(y_test,np.around(y_pred))\n",
    "            # print('Test ACC is', acc)\n",
    "            print(f'With {num_cur_features},{xai_method.get_name()} get ACC:{acc} AUC:{auc_score}')\n",
    "            acc_list.append(acc)\n",
    "            auc_list.append(auc_score)\n",
    "            feature_list.append(np.where(select_arr==1)[0])\n",
    "            \n",
    "            xai = xai_method(model)\n",
    "        \n",
    "            num_remove = int(num_cur_features*(1-reduce_rate))\n",
    "            if num_cur_features - num_remove<=num_select:\n",
    "                num_remove = num_cur_features - num_select\n",
    "            # print(num_remove)\n",
    "            # print('num_remove', num_remove)\n",
    "            xai_attr_test = xai.attribute(Tensor(X_test[...,bool_arr]).to(device))\n",
    "            abs_xai_attr_test = np.abs(xai_attr_test.detach().cpu().numpy()).mean(0)\n",
    "            inds = np.argpartition(abs_xai_attr_test, num_remove)[:num_remove]\n",
    "            inds_to_remove = remaining_inds[inds]\n",
    "            select_arr[inds_to_remove] = 0\n",
    "            \n",
    "            remaining_inds = np.nonzero(select_arr)[0]\n",
    "            num_cur_features -= num_remove\n",
    "            if num_remove == 0:\n",
    "                resuming = False\n",
    "        # np.save(f'./result/{xai_method.get_name()}_feature_final.npy',np.where(select_arr==1)[0])\n",
    "        elapsed_time = time.time() - start_time\n",
    "        dict_method = {}\n",
    "        dict_method['auc'] = auc_list\n",
    "        dict_method['acc'] = acc_list\n",
    "        dict_method['feat'] = feature_list\n",
    "        dict_method['time'] = elapsed_time\n",
    "        with open(f'./result/{xai_method.get_name()}_{repeat}.pkl', 'wb') as f:\n",
    "            pickle.dump(dict_method, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c373b3a6-a8fe-46db-bdbe-974da1e1b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_saliency = np.load('Saliency_feature.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95542401-3cb1-43da-8c08-7ccc18ff6b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_saliency.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f74e7dbd-34bb-4436-82ad-114aa172d207",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_arr = np.array(select_arr, dtype='bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "83f315d3-f4a0-457f-a06e-0104148be04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1204, 73)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[...,bool_arr].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e4f441d4-26ac-43b3-acda-3560dd558559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5100a33-80e2-40d1-9c80-03ba39fe5a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score is: 0\n",
      "best features: [  0   1  14  17  23  24  27  28  29  38  50  51  52  54  55  62  63  73\n",
      "  74  75  76  79  88  89  90  93  94 125 127 129 130 137 138 147 151 154\n",
      " 157 158 164 166 193 254 255 256 257 258 259 273 274 275 276 277 278 279\n",
      " 280 281 289 291 297 298 299 300 301 302 311 323 324 325 326 330 332 334\n",
      " 368]\n"
     ]
    }
   ],
   "source": [
    "print('The best score is:', best_score)\n",
    "print('best features:', np.where(select_arr==1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "baa2265f-bc56-47d4-9f8a-5e39abb58c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27da6586-0db1-4790-8772-21641f0ed2dd",
   "metadata": {},
   "source": [
    "# XGboost and SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664c4d6d-8b18-49e3-b9d8-c08ab056ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=500, learning_rate=0.05, random_state=156).fit(X_train, np.squeeze(y_train))\n",
    "clf.score(X_test, np.squeeze(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdba671-ea1f-40d7-a76a-cb7462beaadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test,y_pred_proba)\n",
    "print('Test auc is', auc(fpr, tpr))\n",
    "acc = balanced_accuracy_score(y_test,np.around(y_pred_proba))\n",
    "print(f'balanced accuarcy score:{acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331e51b9-55ea-4ceb-8562-9ebb834eb899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a98104-64c5-4232-805c-124a443ae61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(gamma='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604a2d44-000a-432b-bb18-29138cc0a330",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, np.squeeze(y_train))\n",
    "y_pred_proba = clf.predict(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test,y_pred_proba)\n",
    "print('Test auc is', auc(fpr, tpr))\n",
    "acc = balanced_accuracy_score(y_test,np.around(y_pred_proba))\n",
    "print(f'balanced accuarcy score:{acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8e6daa-3625-40e0-9eda-f7c89d38a203",
   "metadata": {},
   "source": [
    "# logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aefe52b0-964f-444b-8f45-e22e61579b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58345724 0.26040545 0.67795407 ... 0.84154498 0.68576292 0.18908735]\n",
      "Test auc is 0.7917090440761909\n",
      "balanced accuarcy score:0.7216080568667986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty=None)\n",
    "clf.fit(X_train, np.squeeze(y_train))\n",
    "y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "print(y_pred_proba)\n",
    "fpr, tpr, thresholds = roc_curve(y_test,y_pred_proba)\n",
    "print('Test auc is', auc(fpr, tpr))\n",
    "acc = balanced_accuracy_score(y_test,np.around(y_pred_proba))\n",
    "print(f'balanced accuarcy score:{acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46667dc-d037-4e37-8bd5-4d52fef3c7fa",
   "metadata": {},
   "source": [
    "# L1 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eaa2db9a-c93a-430f-b1d7-510da59a1616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dde50c13-f1e0-4007-a933-baa2176f05ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57961152 0.2762406  0.67486701 ... 0.82669343 0.65260206 0.20646377]\n",
      "Test auc is 0.7894441557867273\n",
      "balanced accuarcy score:0.7065677614778292\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty='l1',solver='liblinear')\n",
    "clf.fit(X_train, np.squeeze(y_train))\n",
    "y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "print(y_pred_proba)\n",
    "fpr, tpr, thresholds = roc_curve(y_test,y_pred_proba)\n",
    "print('Test auc is', auc(fpr, tpr))\n",
    "acc = balanced_accuracy_score(y_test,np.around(y_pred_proba))\n",
    "print(f'balanced accuarcy score:{acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "888d6f25-f136-413e-a63a-f0e52401e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "60cb8937-4949-4c11-a078-418df240bbdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "02ab466e-4a75-4596-9087-1e74cf213e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,  12,  13,  17,  23,  24,  27,  28,  29,  30,  32,\n",
       "        38,  45,  46,  48,  49,  50,  54,  55,  62,  63,  64,  73,  74,\n",
       "        75,  76,  78,  81,  87,  89,  93,  94, 111, 113, 114, 147, 149,\n",
       "       150, 153, 156, 158, 164, 166, 182, 193, 196, 208, 224, 255, 259,\n",
       "       263, 273, 274, 276, 277, 280, 281, 284, 289, 290, 291, 309, 310,\n",
       "       312, 324, 326, 328, 330, 332, 368])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(coef!=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "196a7e32-eede-499d-9102-3a0d40df24dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_coef = coef[:,np.where(coef!=0)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "18c190db-1526-4ef0-9c7c-361d5107a093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 72)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero_coef.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e80ad9-ddbc-413e-8ca2-a445f12c8133",
   "metadata": {},
   "source": [
    "# RFE logstic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7765b842-63a5-4fb8-84db-f9579fd64406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41823ccf-5dce-4656-a05c-b1bfc6c7a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list = []\n",
    "auc_list = []\n",
    "acc_list = []\n",
    "feature_list = []\n",
    "for num_feature in [369,185,93,47,24,12,6,3]:\n",
    "    estimator = LogisticRegression(penalty=None)\n",
    "    selector = RFE(estimator, n_features_to_select=5, step=1)\n",
    "    selector = selector.fit(X_train, np.squeeze(y_train))\n",
    "    selected_RFE = selector.ranking_\n",
    "    selected_RFE[selected_RFE != 1] = 0\n",
    "    bool_arr = np.array(selected_RFE, dtype='bool') \n",
    "    X_train_selected = X_train[...,bool_arr]\n",
    "    X_test_selected = X_test[...,bool_arr]\n",
    "    clf = LogisticRegression(penalty=None)\n",
    "    clf.fit(X_train_selected, np.squeeze(y_train))\n",
    "    \n",
    "    y_pred_proba_linear = clf.predict_proba(X_test_selected)[:,1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test,y_pred_proba_linear)\n",
    "    \n",
    "    acc = balanced_accuracy_score(y_test,np.around(y_pred_proba_linear))\n",
    "    print(f'With {num_feature} in RFE')\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    print('Test auc is', auc_score)\n",
    "    print(f'balanced accuarcy score:{acc}')\n",
    "    num_list.append(num_feature)\n",
    "    acc_list.append(acc)\n",
    "    auc_list.append(auc_list)\n",
    "\n",
    "dict_method = {}\n",
    "dict_method['auc'] = auc_list\n",
    "dict_method['acc'] = acc_list\n",
    "dict_method['feat'] = feature_list\n",
    "with open(f'./result/linear.pkl', 'wb') as f:\n",
    "    pickle.dump(dict_method, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0bfbfd-35e3-4a29-9249-84f2f3c73934",
   "metadata": {},
   "source": [
    "# RFE svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "88f4fcc2-4031-475f-83e3-96c105225cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4ca78886-f88a-462f-8083-dae2b159db02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test auc is 0.48835772798125077\n",
      "balanced accuarcy score:0.4937235371502482\n"
     ]
    }
   ],
   "source": [
    "estimator = SVC(                    \n",
    "            kernel = 'linear',\n",
    "            probability = True,\n",
    "            random_state = 42) \n",
    "selector = RFE(estimator, n_features_to_select=3, step=1)\n",
    "selector = selector.fit(X_train, np.squeeze(y_train))\n",
    "\n",
    "selected_RFE = selector.ranking_\n",
    "selected_RFE[selected_RFE != 1] = 0\n",
    "\n",
    "bool_arr = np.array(selected_RFE, dtype='bool') \n",
    "X_train_selected = X_train[...,bool_arr]\n",
    "X_test_selected = X_test[...,bool_arr]\n",
    "\n",
    "X_train_selected.shape\n",
    "\n",
    "clf = LogisticRegression(penalty=None)\n",
    "clf.fit(X_train_selected, np.squeeze(y_train))\n",
    "\n",
    "y_pred_proba_linear = clf.predict_proba(X_test_selected)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test,y_pred_proba_linear)\n",
    "print('Test auc is', auc(fpr, tpr))\n",
    "acc = balanced_accuracy_score(y_test,np.around(y_pred_proba_linear))\n",
    "print(f'balanced accuarcy score:{acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d3d4c3-b754-465f-aafe-e87ab78140fd",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "bd268095-3559-4855-a77f-c777c4f9fb6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "649b6a11-ee39-438f-80b9-37450336d2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test auc is 0.7285395270681098\n",
      "balanced accuarcy score:0.664920901643875\n"
     ]
    }
   ],
   "source": [
    "estimator = DecisionTreeClassifier()\n",
    "selector = RFE(estimator, n_features_to_select=3, step=1)\n",
    "selector = selector.fit(X_train, np.squeeze(y_train))\n",
    "\n",
    "selected_RFE = selector.ranking_\n",
    "selected_RFE[selected_RFE != 1] = 0\n",
    "\n",
    "bool_arr = np.array(selected_RFE, dtype='bool') \n",
    "X_train_selected = X_train[...,bool_arr]\n",
    "X_test_selected = X_test[...,bool_arr]\n",
    "\n",
    "X_train_selected.shape\n",
    "\n",
    "clf = LogisticRegression(penalty=None)\n",
    "clf.fit(X_train_selected, np.squeeze(y_train))\n",
    "\n",
    "y_pred_proba_linear = clf.predict_proba(X_test_selected)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test,y_pred_proba_linear)\n",
    "print('Test auc is', auc(fpr, tpr))\n",
    "acc = balanced_accuracy_score(y_test,np.around(y_pred_proba_linear))\n",
    "print(f'balanced accuarcy score:{acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f352c8da-b9d5-44ce-adde-50cf876af554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 13,  16, 276])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb3e32aa-3d12-443c-92b8-40489b9d6a87",
   "metadata": {},
   "source": [
    "# Curve with repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05797962-a432-4b85-9fb3-f5f000869930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "185db20e-1aa9-4cb1-b4d3-3799f90c8c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_estimator(method):\n",
    "#     if method =='linear':\n",
    "#         estimator = LogisticRegression(penalty=None)\n",
    "#     elif method == 'SVM':\n",
    "#         estimator = SVC(kernel = 'linear',probability = True) \n",
    "#     elif method =='DT':\n",
    "#         estimator = DecisionTreeClassifier()\n",
    "#     else:\n",
    "#         raise 'wrong method'\n",
    "#     return estimator\n",
    "# for repeat in range(2,6):\n",
    "#     # for method in ['linear','DT']:\n",
    "#     for method in ['DT']:\n",
    "#         auc_list = []\n",
    "#         acc_list = []\n",
    "#         feature_list = []\n",
    "#         for num_feature in [369,185,93,47,24,12,6,3]:\n",
    "#             estimator = get_estimator(method)\n",
    "#             selector = RFE(estimator, n_features_to_select=num_feature)\n",
    "#             selector = selector.fit(X_train, np.squeeze(y_train))\n",
    "#             selected_RFE = selector.ranking_\n",
    "#             selected_RFE[selected_RFE != 1] = 0\n",
    "#             bool_arr = np.array(selected_RFE, dtype='bool') \n",
    "#             X_train_selected = X_train[...,bool_arr]\n",
    "#             X_test_selected = X_test[...,bool_arr]\n",
    "#             clf = get_estimator(method)\n",
    "#             clf.fit(X_train_selected, np.squeeze(y_train))\n",
    "            \n",
    "#             y_pred_proba_linear = clf.predict_proba(X_test_selected)[:,1]\n",
    "#             fpr, tpr, thresholds = roc_curve(y_test,y_pred_proba_linear)\n",
    "            \n",
    "#             acc = balanced_accuracy_score(y_test,np.around(y_pred_proba_linear))\n",
    "#             print(f'With {num_feature} in RFE')\n",
    "#             auc_score = auc(fpr, tpr)\n",
    "#             print('Test auc is', auc_score)\n",
    "#             print(f'balanced accuarcy score:{acc}')\n",
    "\n",
    "#             acc_list.append(acc)\n",
    "#             auc_list.append(auc_score)\n",
    "#             feature_list.append(np.where(selected_RFE==1)[0])\n",
    "#             # print(np.where(selected_RFE==1)[0])\n",
    "#             print(f'With{num_feature},{method} get ACC:{acc} AUC:{auc_score}')\n",
    "#         dict_method = {}\n",
    "#         dict_method['auc'] = auc_list\n",
    "#         dict_method['acc'] = acc_list\n",
    "#         dict_method['feat'] = feature_list\n",
    "#         print(dict_method)\n",
    "#         # with open(f'./result/{method}_{repeat}.pkl', 'wb') as f:\n",
    "#         #     pickle.dump(dict_method, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7460e1b2-c079-471c-855f-2d74b51c60a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(name):\n",
    "    acc_curve = []\n",
    "    auc_curve = []\n",
    "    feature_curve = []\n",
    "    for i in range(1,6):\n",
    "        with open(f'./result/{name}_{i}.pkl','rb') as file:\n",
    "            i_th_result = pickle.load(file)\n",
    "            acc_curve.append(i_th_result['acc'])\n",
    "            auc_curve.append(i_th_result['auc'])\n",
    "            feature_curve.append(i_th_result['feat'])\n",
    "    return acc_curve, auc_curve, feature_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bd2b96f5-f43c-49fe-bada-b500937aea78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 369,DT get ACC:0.6675768597234045 AUC:0.6717791326265518\n",
      "With 185,DT get ACC:0.6566628342748488 AUC:0.6592911549133842\n",
      "With 93,DT get ACC:0.6724355218501608 AUC:0.6768519849210122\n",
      "With 47,DT get ACC:0.6822191759620593 AUC:0.6865126524204871\n",
      "With 24,DT get ACC:0.681420453917331 AUC:0.6858134251633372\n",
      "With 12,DT get ACC:0.6812822667123606 AUC:0.6822260853223079\n",
      "With 6,DT get ACC:0.675428656709818 AUC:0.6773162939297124\n",
      "With 3,DT get ACC:0.648542954110793 AUC:0.6428524050101153\n",
      "With 369,DT get ACC:0.6666454779619045 AUC:0.6702715102203257\n",
      "With 185,DT get ACC:0.6589263406922626 AUC:0.6628522391854693\n",
      "With 93,DT get ACC:0.6627209613407475 AUC:0.6668624318737081\n",
      "With 47,DT get ACC:0.6816194434924882 AUC:0.6852427120068099\n",
      "With 24,DT get ACC:0.6721674386725185 AUC:0.6760919552936755\n",
      "With 12,DT get ACC:0.6578567717257924 AUC:0.6581925666338704\n",
      "With 6,DT get ACC:0.6708380777607039 AUC:0.672612401472523\n",
      "With 3,DT get ACC:0.6468791801629503 AUC:0.6410283339045071\n",
      "With 369,DT get ACC:0.6709044076190898 AUC:0.6752365764949092\n",
      "With 185,DT get ACC:0.6663138286699758 AUC:0.6705465027582166\n",
      "With 93,DT get ACC:0.6621875587295621 AUC:0.665675403783013\n",
      "With 47,DT get ACC:0.6816222072365876 AUC:0.6847742573819604\n",
      "With 24,DT get ACC:0.6843472589186022 AUC:0.6880437666515581\n",
      "With 12,DT get ACC:0.6746962645234753 AUC:0.6783969178725804\n",
      "With 6,DT get ACC:0.6616513923742773 AUC:0.660638480161845\n",
      "With 3,DT get ACC:0.6532661927766784 AUC:0.6479528947455697\n",
      "With 369,DT get ACC:0.6695087168488896 AUC:0.6727063687719027\n",
      "With 185,DT get ACC:0.6614551665432193 AUC:0.6654736504637563\n",
      "With 93,DT get ACC:0.6713051505135037 AUC:0.6757326685607526\n",
      "With 47,DT get ACC:0.676429132073803 AUC:0.6810321478713643\n",
      "With 24,DT get ACC:0.6590590004090341 AUC:0.6621405750798722\n",
      "With 12,DT get ACC:0.6615850625158914 AUC:0.6621157013829775\n",
      "With 6,DT get ACC:0.6762937086129321 AUC:0.6782172745061189\n",
      "With 3,DT get ACC:0.6444166841703793 AUC:0.638324010303238\n",
      "With 369,DT get ACC:0.6573952264611915 AUC:0.6612368307593663\n",
      "With 185,DT get ACC:0.6646500547221331 AUC:0.6688177808240379\n",
      "With 93,DT get ACC:0.6681765921929756 AUC:0.6724451949545088\n",
      "With 47,DT get ACC:0.673565893186818 AUC:0.6779713012812718\n",
      "With 24,DT get ACC:0.6687735609184474 AUC:0.6723318814464332\n",
      "With 12,DT get ACC:0.6760256254352897 AUC:0.6802887007086239\n",
      "With 6,DT get ACC:0.6771587605160463 AUC:0.6791182550825254\n",
      "With 3,DT get ACC:0.6438832815591938 AUC:0.6376980222647225\n",
      "With 369,SVM get ACC:0.7079689797362283 AUC:0.7877942005593818\n",
      "With 185,SVM get ACC:0.7079689797362283 AUC:0.7885224471295753\n",
      "With 93,SVM get ACC:0.7059735564964569 AUC:0.7870300253158959\n",
      "With 47,SVM get ACC:0.7022480294504572 AUC:0.787611793448821\n",
      "With 24,SVM get ACC:0.6987242557237141 AUC:0.7811197585593155\n",
      "With 12,SVM get ACC:0.6985915960069425 AUC:0.7226596614966228\n",
      "With 6,SVM get ACC:0.691671180782029 AUC:0.7101744475275544\n",
      "With 3,SVM get ACC:0.49061985252661483 AUC:0.5115731784162642\n",
      "With 369,SVM get ACC:0.7087677017809566 AUC:0.7879406789966503\n",
      "With 185,SVM get ACC:0.7079689797362283 AUC:0.7883842599246051\n",
      "With 93,SVM get ACC:0.7059735564964569 AUC:0.7869056568314227\n",
      "With 47,SVM get ACC:0.7022480294504572 AUC:0.7876698320749085\n",
      "With 24,SVM get ACC:0.6979255336789856 AUC:0.7811183766872657\n",
      "With 12,SVM get ACC:0.6985915960069425 AUC:0.7226596614966228\n",
      "With 6,SVM get ACC:0.691671180782029 AUC:0.7101744475275544\n",
      "With 3,SVM get ACC:0.5071802071702577 AUC:0.5075505488795782\n",
      "With 369,SVM get ACC:0.7079689797362283 AUC:0.787904750323358\n",
      "With 185,SVM get ACC:0.7079689797362283 AUC:0.788519683385476\n",
      "With 93,SVM get ACC:0.7059735564964569 AUC:0.7868697281581304\n",
      "With 47,SVM get ACC:0.7022480294504572 AUC:0.7875924472401252\n",
      "With 24,SVM get ACC:0.6987242557237141 AUC:0.7811197585593155\n",
      "With 12,SVM get ACC:0.6985915960069425 AUC:0.7226596614966228\n",
      "With 6,SVM get ACC:0.691671180782029 AUC:0.7101744475275544\n",
      "With 3,SVM get ACC:0.5088412173740009 AUC:0.5092585427330113\n",
      "With 369,SVM get ACC:0.7079689797362283 AUC:0.7878522391854692\n",
      "With 185,SVM get ACC:0.7079689797362283 AUC:0.7883966967730525\n",
      "With 93,SVM get ACC:0.7059735564964569 AUC:0.7868669644140309\n",
      "With 47,SVM get ACC:0.7022480294504572 AUC:0.7876670683308091\n",
      "With 24,SVM get ACC:0.6987242557237141 AUC:0.7811197585593155\n",
      "With 12,SVM get ACC:0.6985915960069425 AUC:0.7226582796245731\n",
      "With 6,SVM get ACC:0.691671180782029 AUC:0.7101744475275544\n",
      "With 3,SVM get ACC:0.5062488254087577 AUC:0.5066523320472711\n",
      "With 369,SVM get ACC:0.7079689797362283 AUC:0.7877969643034811\n",
      "With 185,SVM get ACC:0.7079689797362283 AUC:0.7884782272239849\n",
      "With 93,SVM get ACC:0.7059735564964569 AUC:0.7870023878749017\n",
      "With 47,SVM get ACC:0.7022480294504572 AUC:0.787611793448821\n",
      "With 24,SVM get ACC:0.6987242557237141 AUC:0.7811197585593155\n",
      "With 12,SVM get ACC:0.6985915960069425 AUC:0.7226582796245731\n",
      "With 6,SVM get ACC:0.691671180782029 AUC:0.7101744475275544\n",
      "With 3,SVM get ACC:0.49255170965209993 AUC:0.5118357341057076\n",
      "With 369,linear get ACC:0.7216080568667986 AUC:0.7917104259482406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 185,linear get ACC:0.7136871662779 AUC:0.7916371867296064\n",
      "With 93,linear get ACC:0.7084968548592149 AUC:0.7908965033109654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 47,linear get ACC:0.7082315354256719 AUC:0.7868490000773849\n",
      "With 24,linear get ACC:0.6686491924339741 AUC:0.7397727649601469\n",
      "With 12,linear get ACC:0.5834816542666681 AUC:0.6410559713455013\n",
      "With 6,linear get ACC:0.5762931558641122 AUC:0.6382811722696973\n",
      "With 3,linear get ACC:0.5557972296229148 AUC:0.6026426921078525\n",
      "With 369,linear get ACC:0.7216080568667986 AUC:0.7917104259482406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 185,linear get ACC:0.7136871662779 AUC:0.7916371867296064\n",
      "With 93,linear get ACC:0.7084968548592149 AUC:0.7908965033109654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 47,linear get ACC:0.7082315354256719 AUC:0.7868490000773849\n",
      "With 24,linear get ACC:0.6686491924339741 AUC:0.7397727649601469\n",
      "With 12,linear get ACC:0.5834816542666681 AUC:0.6410559713455013\n",
      "With 6,linear get ACC:0.5762931558641122 AUC:0.6382811722696973\n",
      "With 3,linear get ACC:0.5557972296229148 AUC:0.6026426921078525\n",
      "With 369,linear get ACC:0.7216080568667986 AUC:0.7917104259482406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 185,linear get ACC:0.7136871662779 AUC:0.7916371867296064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 93,linear get ACC:0.7084968548592149 AUC:0.7908965033109654\n",
      "With 47,linear get ACC:0.7082315354256719 AUC:0.7868490000773849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 24,linear get ACC:0.6686491924339741 AUC:0.7397727649601469\n",
      "With 12,linear get ACC:0.5834816542666681 AUC:0.6410559713455013\n",
      "With 6,linear get ACC:0.5762931558641122 AUC:0.6382811722696973\n",
      "With 3,linear get ACC:0.5557972296229148 AUC:0.6026426921078525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 369,linear get ACC:0.7216080568667986 AUC:0.7917104259482406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 185,linear get ACC:0.7136871662779 AUC:0.7916371867296064\n",
      "With 93,linear get ACC:0.7084968548592149 AUC:0.7908965033109654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 47,linear get ACC:0.7082315354256719 AUC:0.7868490000773849\n",
      "With 24,linear get ACC:0.6686491924339741 AUC:0.7397727649601469\n",
      "With 12,linear get ACC:0.5834816542666681 AUC:0.6410559713455013\n",
      "With 6,linear get ACC:0.5762931558641122 AUC:0.6382811722696973\n",
      "With 3,linear get ACC:0.5557972296229148 AUC:0.6026426921078525\n",
      "With 369,linear get ACC:0.7216080568667986 AUC:0.7917104259482406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 185,linear get ACC:0.7136871662779 AUC:0.7916371867296064\n",
      "With 93,linear get ACC:0.7084968548592149 AUC:0.7908965033109654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zwkan/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 47,linear get ACC:0.7082315354256719 AUC:0.7868490000773849\n",
      "With 24,linear get ACC:0.6686491924339741 AUC:0.7397727649601469\n",
      "With 12,linear get ACC:0.5834816542666681 AUC:0.6410559713455013\n",
      "With 6,linear get ACC:0.5762931558641122 AUC:0.6382811722696973\n",
      "With 3,linear get ACC:0.5557972296229148 AUC:0.6026426921078525\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def get_estimator(method):\n",
    "    if method =='linear':\n",
    "        estimator = LogisticRegression(penalty=None)\n",
    "    elif method == 'SVM':\n",
    "        estimator = SVC(kernel = 'linear',probability = True) \n",
    "    elif method =='DT':\n",
    "        estimator = DecisionTreeClassifier()\n",
    "    else:\n",
    "        raise 'wrong method'\n",
    "    return estimator\n",
    "    \n",
    "for method in ['DT','SVM','linear']:\n",
    "    for repeat in range(1,6):\n",
    "        reduce_rate = 0.5\n",
    "        num_cur_features = X_train.shape[-1]\n",
    "        select_arr = np.ones(num_cur_features)\n",
    "        remaining_inds = np.nonzero(select_arr)[0]\n",
    "        num_select = 3\n",
    "        num_list = []\n",
    "        auc_list = []\n",
    "        acc_list = []\n",
    "        feature_list = []\n",
    "        resuming = True\n",
    "        start_time = time.time()\n",
    "        while resuming:\n",
    "            bool_arr = np.array(select_arr, dtype='bool') \n",
    "            X_train_selected = X_train[...,bool_arr]\n",
    "            X_test_selected = X_test[...,bool_arr]\n",
    "            clf = get_estimator(method)\n",
    "            clf.fit(X_train_selected, np.squeeze(y_train))\n",
    "            \n",
    "            y_pred_proba = clf.predict_proba(X_test_selected)[:,1]\n",
    "            acc = balanced_accuracy_score(y_test,np.around(y_pred_proba))\n",
    "            fpr, tpr, thresholds = roc_curve(y_test,y_pred_proba)\n",
    "            \n",
    "\n",
    "            auc_score = auc(fpr, tpr)\n",
    "            acc = balanced_accuracy_score(y_test,np.around(y_pred_proba))\n",
    "            print(f'With {num_cur_features},{method} get ACC:{acc} AUC:{auc_score}')\n",
    "            acc_list.append(acc)\n",
    "            auc_list.append(auc_score)\n",
    "            feature_list.append(np.where(select_arr==1)[0])\n",
    "            \n",
    "            num_remove = int(num_cur_features*(1-reduce_rate))\n",
    "            if num_cur_features - num_remove<=num_select:\n",
    "                num_remove = num_cur_features - num_select\n",
    "            num_cur_features -= num_remove\n",
    "            # print(num_cur_features)\n",
    "            estimator = get_estimator(method)\n",
    "            if num_remove == 0:\n",
    "                resuming = False\n",
    "                continue\n",
    "            selector = RFE(estimator, n_features_to_select=num_cur_features,step=num_remove)\n",
    "            selector = selector.fit(X_train_selected, np.squeeze(y_train))\n",
    "            selected_RFE = selector.ranking_\n",
    "            selected_RFE[selected_RFE != 1] = 0\n",
    "            bool_arr = np.array(selected_RFE, dtype='bool') \n",
    "\n",
    "            inds = np.where(selected_RFE==0)[0]\n",
    "            # print(inds)\n",
    "            inds_to_remove = remaining_inds[inds]\n",
    "            # print(inds_to_remove)\n",
    "            select_arr[inds_to_remove] = 0\n",
    "            remaining_inds = np.nonzero(select_arr)[0]\n",
    "            \n",
    "            # print(remaining_inds,num_cur_features)\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        dict_method = {}\n",
    "        dict_method['auc'] = auc_list\n",
    "        dict_method['acc'] = acc_list\n",
    "        dict_method['feat'] = feature_list\n",
    "        dict_method['time'] = elapsed_time\n",
    "        with open(f'./result/{method}_{repeat}.pkl', 'wb') as f:\n",
    "            pickle.dump(dict_method, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b8a04d58-ed4b-46a9-a744-ea5aad766af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'linear'\n",
    "Linear_acc, Linear_auc, Linear_feat = get_result(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d722be8c-825a-4c6a-abf3-2ac702431209",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'DT'\n",
    "DT_acc, DT_auc, DT_feat = get_result(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c4aae3fa-ab79-4465-a796-9375da958413",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'SVM'\n",
    "SVM_acc, SVM_auc, SVM_feat = get_result(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8a27093e-09f8-4a60-8d06-992d0bc9aa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(369,)\n",
      "(185,)\n",
      "(93,)\n",
      "(47,)\n",
      "(24,)\n",
      "(12,)\n",
      "(6,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(SVM_feat[0])):\n",
    "    print(SVM_feat[0][i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ef065ede-a9c3-4672-a42d-1a84ab7603bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear_feat = [284,328,368]\n",
    "# DT_feat = [1,182,368]\n",
    "# SVM_feat = [13,16,276]\n",
    "# feats_RFE = [Linear_feat, DT_feat, SVM_feat]\n",
    "# name = ['linear','DT','SVM']\n",
    "feats_RFE = [ DT_feat]\n",
    "name = ['DT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "94cd7c0f-259c-41ae-a905-9cbc6cec21b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "(4812, 369)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93cbbb8caf242c491399c8c8fabbf78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.7008539736270905\n",
      "With feat [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368] from DT, test auc is:0.7753849895530474 test acc is:0.7346584565041954\n",
      "(4812, 185)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6270d420a4546a8beb19f069da31548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.5745718479156494\n",
      "With feat [  0   1   2   4   7   8   9  10  11  12  13  14  15  16  17  18  19  20\n",
      "  21  22  23  27  39  48  49  50  51  52  53  54  55  56  57  58  59  60\n",
      "  61  62  63  73  74  76  79  81  82  83  84  85  86  87  88  89  90  91\n",
      "  92  93  94  96 111 112 113 114 115 116 117 118 119 120 121 122 123 124\n",
      " 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142\n",
      " 143 144 145 146 147 149 150 151 154 157 159 160 161 162 163 164 166 169\n",
      " 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 187 190\n",
      " 193 240 241 254 255 256 257 258 259 273 274 275 276 277 278 279 280 283\n",
      " 289 291 292 297 298 299 300 301 302 303 304 310 311 320 321 322 323 324\n",
      " 325 326 327 328 329 330 331 332 334 335 336 337 340 343 346 347 348 349\n",
      " 350 351 355 356 368] from DT, test auc is:0.7442997777949745 test acc is:0.7230092751251976\n",
      "(4812, 93)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b19ea81a1d4fceacc9534f04f5f20b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.6476767659187317\n",
      "With feat [  0   1   2   4  10  11  13  14  15  16  17  20  23  27  39  59  60  61\n",
      "  62  63  73  74  76  79  81  82  83  84  85  86  87  88  89  90  93 112\n",
      " 113 116 125 127 129 130 137 138 147 150 151 154 157 159 164 166 173 177\n",
      " 182 187 190 193 240 241 254 255 258 259 274 275 276 277 278 279 280 289\n",
      " 291 292 297 298 299 300 301 302 311 323 324 325 326 328 329 330 331 337\n",
      " 340 343 368] from DT, test auc is:0.7582635948572249 test acc is:0.7198751893164708\n",
      "(4812, 47)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39dd3956ea24311964b1867adea63b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.8188439011573792\n",
      "With feat [  0   1   2  10  11  14  15  16  17  76  89 113 125 127 137 138 147 151\n",
      " 154 164 166 182 187 190 193 274 275 276 277 278 279 280 289 292 297 299\n",
      " 300 302 323 324 325 326 328 329 330 331 368] from DT, test auc is:0.7773804127928187 test acc is:0.7180151895375704\n",
      "(4812, 24)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7fe4e254aa24449a68e6e63ae790337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.0462221205234528\n",
      "With feat [  1  11  15 137 154 164 182 190 193 274 275 276 277 289 297 323 324 325\n",
      " 326 328 329 330 331 368] from DT, test auc is:0.7734766242524073 test acc is:0.7163431243574294\n",
      "(4812, 12)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df83db7aa9bc43d5b97e5784b0f69917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.4176270067691803\n",
      "With feat [  1  11 164 182 190 277 324 326 328 329 331 368] from DT, test auc is:0.7797917795195507 test acc is:0.7218042826978565\n",
      "(4812, 6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51da6ff749b84827b6f0392581724e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.5638334155082703\n",
      "With feat [  1 182 326 329 331 368] from DT, test auc is:0.7788728346064981 test acc is:0.7232745945587407\n",
      "(4812, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f913342689f4a66a0092ddf50aec8eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.7136850357055664\n",
      "With feat [  1 182 368] from DT, test auc is:0.7606680522237086 test acc is:0.7164149817040141\n",
      "(4812, 369)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9b4800c2214d1ca551d77e84668f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.651178389787674\n",
      "With feat [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368] from DT, test auc is:0.760307383618736 test acc is:0.7314608045811822\n",
      "(4812, 185)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22749f802ec4d53ae8c5e0f9fb83e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.621159702539444\n",
      "With feat [  0   1   2   3   4  10  11  12  13  14  15  16  17  19  23  24  27  30\n",
      "  39  46  54  65  67  68  69  70  71  72  73  74  75  76  77  78  79  80\n",
      "  81  82  88  89  90  93  98 112 113 114 123 125 126 127 130 137 138 147\n",
      " 149 150 151 154 157 158 164 166 182 184 185 186 187 188 189 190 191 192\n",
      " 193 194 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234\n",
      " 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252\n",
      " 255 257 273 274 275 276 277 278 279 280 289 291 292 297 298 299 300 301\n",
      " 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319\n",
      " 320 321 322 323 324 325 326 327 328 329 330 331 332 336 337 338 339 340\n",
      " 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358\n",
      " 359 360 361 367 368] from DT, test auc is:0.7638684678908211 test acc is:0.7284013398631395\n",
      "(4812, 93)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef94ac5d472a45869ac22292f2bcfdc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.6388844549655914\n",
      "With feat [  0   1   2   3   4  10  11  12  13  14  16  17  23  73  75  76  79  82\n",
      "  88  89  90  93  98 112 113 114 123 125 126 127 130 137 138 147 149 150\n",
      " 151 154 157 158 164 166 182 187 190 193 224 240 241 255 273 274 275 276\n",
      " 277 278 279 280 289 291 292 297 299 300 301 302 310 311 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 336 337 338 340 341 342 343 344 345\n",
      " 346 355 368] from DT, test auc is:0.7688058967244104 test acc is:0.7313253811203113\n",
      "(4812, 47)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978f74d1d1fd44c8bfbbc1c7233e34fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.7991389632225037\n",
      "With feat [  0   1   2  11  12  13  14  16  17  23  76  79  88 125 126 137 151 154\n",
      " 157 164 166 182 187 190 193 240 274 275 276 277 279 280 289 292 297 299\n",
      " 300 301 302 323 324 325 326 328 329 331 368] from DT, test auc is:0.7898448986811413 test acc is:0.7363885603104238\n",
      "(4812, 24)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0848969c70348fd8d60aaf3d6fa7e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.9545502960681915\n",
      "With feat [  1  11  12 154 157 164 182 190 193 274 275 276 277 279 289 297 323 324\n",
      " 325 326 328 329 331 368] from DT, test auc is:0.7785094022574262 test acc is:0.7169483843151995\n",
      "(4812, 12)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5cf5988a4d54ac9a91776757f373414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.4516369998455048\n",
      "With feat [  1  11 164 182 190 289 324 326 328 329 331 368] from DT, test auc is:0.7867370684413588 test acc is:0.725330820168699\n",
      "(4812, 6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce6f5add2aa42bba5c3cc14f4245788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.5725897550582886\n",
      "With feat [  1 182 326 329 331 368] from DT, test auc is:0.7779055241717059 test acc is:0.7257978929214985\n",
      "(4812, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92255189db5b46dfbb89e7af1d2e850e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.6992295384407043\n",
      "With feat [  1 182 368] from DT, test auc is:0.7620112318560199 test acc is:0.7178079087301148\n",
      "(4812, 369)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90b941a52bf45c5aeda47681287e0ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.6724514961242676\n",
      "With feat [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368] from DT, test auc is:0.7491612036658302 test acc is:0.7207374774754856\n",
      "(4812, 185)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283d9f486bbd44019fbf71113070c961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.6267584562301636\n",
      "With feat [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  25  26  27  28  29  30  48  54  62  63  73  76\n",
      "  77  79  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100\n",
      " 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136\n",
      " 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154\n",
      " 155 156 157 158 159 160 161 162 163 164 165 166 168 182 187 190 193 240\n",
      " 241 255 256 257 258 259 273 274 275 276 277 279 280 286 289 290 292 297\n",
      " 298 299 300 301 302 310 311 321 322 323 324 325 326 327 328 329 330 331\n",
      " 332 333 334 335 336 337 338 339 340 341 342 343 345 346 347 348 349 350\n",
      " 351 364 365 367 368] from DT, test auc is:0.7441892280309982 test acc is:0.7198116232021845\n",
      "(4812, 93)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deeacc93d15f40c3a3623cbad1ffc8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.6493271589279175\n",
      "With feat [  0   1   2   3   4  10  11  12  13  14  15  16  17  23  27  29  76  79\n",
      "  86  87  88  89  90  91  92  93  94  95  96  97  99 108 113 115 118 125\n",
      " 126 127 129 130 137 138 147 148 151 154 157 158 160 164 166 182 187 190\n",
      " 193 240 241 255 274 275 276 277 279 280 286 289 290 292 297 298 299 300\n",
      " 301 302 310 311 321 322 323 324 325 326 327 328 329 330 331 332 335 337\n",
      " 340 342 368] from DT, test auc is:0.7658915285715865 test acc is:0.7304022905911096\n",
      "(4812, 47)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7213ad54600748b3aaae30f5ad2eccbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.8299391269683838\n",
      "With feat [  0   1   2  10  11  13  14  15  16  17  76  79  88 126 127 129 137 148\n",
      " 151 154 157 164 166 182 187 190 193 274 275 276 277 279 280 289 292 297\n",
      " 299 300 323 324 325 326 328 329 330 331 368] from DT, test auc is:0.7806416308301183 test acc is:0.7262732569065966\n",
      "(4812, 24)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3e7259e8b94896b92feac74db68a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.0071535408496857\n",
      "With feat [  1  11  15  16 137 164 182 187 190 193 274 275 276 277 289 297 323 324\n",
      " 325 326 328 329 331 368] from DT, test auc is:0.7758617354101949 test acc is:0.7174845506704843\n",
      "(4812, 12)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876c885cd18547af9053e404e4027e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.453231304883957\n",
      "With feat [  1 164 182 277 289 323 324 326 328 329 331 368] from DT, test auc is:0.7878784947544136 test acc is:0.7194164077959693\n",
      "(4812, 6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8aec0478d344edb80e5c7888b892a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.6184103190898895\n",
      "With feat [  1 182 328 329 331 368] from DT, test auc is:0.7808599666139714 test acc is:0.7278624097637552\n",
      "(4812, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010d9f3c5c934f9bb99df6a07051a53e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.6948357820510864\n",
      "With feat [  1 182 368] from DT, test auc is:0.7594492410758703 test acc is:0.7161441347822722\n",
      "(4812, 369)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616e52ffe53d436587ee1b73f47feee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.594884604215622\n",
      "With feat [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368] from DT, test auc is:0.750493328321744 test acc is:0.7233381606730269\n",
      "(4812, 185)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a81ec70564674b7dafc5c68b0826ad03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.5524109303951263\n",
      "With feat [  0   1   2   3   4  10  11  12  13  14  15  16  17  18  19  20  21  22\n",
      "  24  25  26  27  28  29  30  31  53  55  60  61  62  63  65  67  73  74\n",
      "  76  79  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97\n",
      "  98  99 100 103 104 105 106 107 108 113 117 118 119 120 121 122 123 124\n",
      " 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142\n",
      " 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 164\n",
      " 166 168 170 177 182 187 190 193 240 241 254 255 258 259 273 274 275 276\n",
      " 277 278 279 280 282 283 284 285 286 287 288 289 290 291 292 293 294 295\n",
      " 296 297 298 299 300 301 302 303 304 311 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 334 335 336 337 338 340 343 346 347 348 349 355 356 357\n",
      " 358 359 360 361 368] from DT, test auc is:0.7536661065478625 test acc is:0.7201460362382126\n",
      "(4812, 93)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e767ccdce5e4116a1c046e2120b6a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.5514217913150787\n",
      "With feat [  0   1   2   3   4  10  11  12  13  14  15  16  17  18  21  22  27  62\n",
      "  74  76  79  88  89  90  91  93  95  97 113 123 125 127 129 130 137 138\n",
      " 140 147 148 150 151 152 153 154 157 164 166 182 187 190 193 240 241 255\n",
      " 258 259 273 274 275 276 277 278 279 280 283 289 291 292 297 298 299 301\n",
      " 302 311 323 324 325 326 328 329 330 331 334 337 340 343 347 357 358 359\n",
      " 360 361 368] from DT, test auc is:0.7628749018870845 test acc is:0.7357197342383675\n",
      "(4812, 47)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9000edea73764782b47c5b6c709081cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.8386216163635254\n",
      "With feat [  0   1   2   4  10  11  13  14  15  16  17  62  76  79  89  90 123 125\n",
      " 147 151 154 164 166 182 187 190 193 274 275 276 277 279 280 289 291 292\n",
      " 297 302 323 324 325 326 328 329 330 331 368] from DT, test auc is:0.7795969355605425 test acc is:0.7214145947798402\n",
      "(4812, 24)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84031063bd554ca3b25162d9b0a6e894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.0982359647750854\n",
      "With feat [  1  15  62 164 182 187 190 193 274 275 276 277 279 289 302 323 324 325\n",
      " 326 328 329 330 331 368] from DT, test auc is:0.7833901743369778 test acc is:0.7182749814829146\n",
      "(4812, 12)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a994a91f816443dda37c365c81c49239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.419725686311722\n",
      "With feat [  1  15 164 182 190 289 324 326 328 329 331 368] from DT, test auc is:0.7807729086748401 test acc is:0.7193500779375837\n",
      "(4812, 6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d384e1415724ef3adaca5d23933d0e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.591853052377701\n",
      "With feat [  1 182 326 329 331 368] from DT, test auc is:0.7752025824424863 test acc is:0.724399438407199\n",
      "(4812, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf92188a5314692a0773dfb959565fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.689613997936249\n",
      "With feat [  1 182 368] from DT, test auc is:0.7596537581392265 test acc is:0.7188056203500006\n",
      "(4812, 369)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba28f4f283441549cd2823783ee6146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.6286557912826538\n",
      "With feat [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368] from DT, test auc is:0.7697013498126181 test acc is:0.7307947422532253\n",
      "(4812, 185)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e71b78ba0d347a6826aaeaea2cef629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.9548037648200989\n",
      "With feat [  0   1   2   3   4  10  11  12  13  14  15  16  17  18  20  21  22  23\n",
      "  24  25  26  27  28  29  36  39  48  50  51  52  53  54  55  56  57  58\n",
      "  59  60  61  62  63  64  73  74  76  79  81  82  83  84  85  86  87  88\n",
      "  89  90  91  92  93  94  95  96  98  99 105 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 154 162 163\n",
      " 164 165 166 167 169 172 173 174 175 176 177 178 179 180 181 182 183 184\n",
      " 185 186 187 188 189 190 193 240 241 255 257 258 259 273 274 275 276 277\n",
      " 278 279 280 282 286 289 292 297 298 299 300 302 310 311 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 340 343 347 348\n",
      " 349 350 360 361 368] from DT, test auc is:0.7503123030832329 test acc is:0.7238660357960136\n",
      "(4812, 93)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd05c70323fe4475aaf64f16fa561154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.6275436282157898\n",
      "With feat [  0   1   2   3   4  10  11  12  13  14  15  16  17  18  23  27  39  48\n",
      "  51  52  53  54  55  56  57  63  64  73  76  79  85  88  89  90  93  95\n",
      " 105 113 116 123 125 126 127 129 137 138 139 147 149 151 154 164 166 167\n",
      " 175 178 182 187 190 193 240 241 257 258 273 274 275 276 277 278 279 280\n",
      " 282 289 297 298 299 300 310 311 323 324 325 326 328 329 330 331 335 337\n",
      " 340 343 368] from DT, test auc is:0.7646934455044939 test acc is:0.7244049658953978\n",
      "(4812, 47)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aaa725245b440c98a9096ed20e56c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.7699767053127289\n",
      "With feat [  0   1   2   4  12  13  16  17  76  88  89  90 125 126 137 151 164 166\n",
      " 182 187 190 193 240 273 274 275 276 277 279 280 289 297 298 299 300 311\n",
      " 323 324 325 326 328 329 330 331 335 340 368] from DT, test auc is:0.7753849895530472 test acc is:0.7274727218457389\n",
      "(4812, 24)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259e9bbb981448e7ba429fc654b83894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.014258861541748\n",
      "With feat [  1  12  17 125 137 164 182 190 193 275 276 277 279 289 297 323 324 325\n",
      " 326 328 329 330 331 368] from DT, test auc is:0.7725645886996031 test acc is:0.7123578053660855\n",
      "(4812, 12)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948341dfebe14c25a5f0f025dd6a93f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.4481990337371826\n",
      "With feat [  1 164 182 190 277 289 324 326 328 329 331 368] from DT, test auc is:0.7796425373381828 test acc is:0.7158926340692262\n",
      "(4812, 6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3495b4b0876547118e7a743886c24eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.573814183473587\n",
      "With feat [  1 182 326 329 331 368] from DT, test auc is:0.7751224338636037 test acc is:0.7214726334059276\n",
      "(4812, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f669686867b4bada17e94ee36db83c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.7070230841636658\n",
      "With feat [  1 182 368] from DT, test auc is:0.7602451993764994 test acc is:0.7203367345810716\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(feats_RFE)):\n",
    "\n",
    "    repeat_times = 6 if name[j]=='DT' else 2\n",
    "    print(repeat_times)\n",
    "    for repeat in range(1,repeat_times):\n",
    "        aucs = []\n",
    "        accs = []\n",
    "        method_feat = feats_RFE[j]\n",
    "        label = name[j]\n",
    "        for step in range(len(method_feat[0])):\n",
    "            feat = method_feat[repeat-1][step]\n",
    "            X_train_select = X_train[...,feat]\n",
    "            X_test_select = X_test[...,feat]\n",
    "            print(X_train_select.shape)\n",
    "            train_set = TensorDataset(Tensor(X_train_select), Tensor(y_train))\n",
    "            train_loader = DataLoader(train_set, batch_size=1000, shuffle=True)\n",
    "            test_set = TensorDataset(Tensor(X_test_select), Tensor(y_test))\n",
    "            test_loader = DataLoader(test_set, batch_size=y_test.shape[0],shuffle=False)\n",
    "            hidden_layer_sizes = (100,100,100)\n",
    "            num_epochs = 500\n",
    "            model = MLPClassifier(X_train_select.shape[-1], hidden_layer_sizes, p=0.0)\n",
    "            model.to(device)\n",
    "            model.train()\n",
    "            # print(model)\n",
    "            criterion = nn.BCELoss(reduction='mean')\n",
    "            optimizer = torch.optim.Adam(model.parameters(), 0.001)\n",
    "            train(model, train_loader, num_epochs, optimizer)\n",
    "            model.eval()\n",
    "            y_pred = model(Tensor(X_test_select).to(device)).detach().cpu().numpy()\n",
    "            \n",
    "            y_test =y_test.astype(int)\n",
    "            \n",
    "            fpr, tpr, thresholds = roc_curve(y_test,y_pred)\n",
    "            ACC = balanced_accuracy_score(y_test,np.around(y_pred))\n",
    "            auc_score = auc(fpr, tpr)\n",
    "            # print(f'With Drop out{p}')\n",
    "            # print('Test auc is', auc(fpr, tpr))\n",
    "            # print('Balanced_accuracy_score is', ACC)\n",
    "            print(f'With feat {feat} from {label}, test auc is:{auc_score} test acc is:{ACC}')\n",
    "            aucs.append(auc_score)\n",
    "            accs.append(ACC)\n",
    "        dict_method = {}\n",
    "        dict_method['auc'] = aucs\n",
    "        dict_method['acc'] = accs\n",
    "        with open(f'./result/feature_{label}_results_{repeat}.pkl', 'wb') as f:\n",
    "            pickle.dump(dict_method, f)\n",
    "    # y_pred_train = model(Tensor(X_train).to(device)).detach().cpu().numpy()\n",
    "    \n",
    "    \n",
    "    # fpr, tpr, thresholds = roc_curve(y_train,y_pred_train)\n",
    "    # ACC = balanced_accuracy_score(y_train,np.around(y_pred_train))\n",
    "    # print(f'With Drop out:{p}')\n",
    "    # print('Train auc is', auc(fpr, tpr))\n",
    "    # print('Balanced_accuracy_score of Train is', ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f6671c37-4ac8-4ee3-844f-7fa575b4d250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': [0.7531175033441303,\n",
       "  0.7537352001503476,\n",
       "  0.7816918535878925,\n",
       "  0.7933852548724809,\n",
       "  0.7974092662812164,\n",
       "  0.7252119791724245,\n",
       "  0.7132808958952874,\n",
       "  0.5305545728909868],\n",
       " 'acc': [0.7119681174480692,\n",
       "  0.7176199741313553,\n",
       "  0.7146959328741833,\n",
       "  0.7292055893960666,\n",
       "  0.721420122268039,\n",
       "  0.6973202737212156,\n",
       "  0.691997302585759,\n",
       "  0.5245033551853368]}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6af8f8cf-4fa5-45ac-8b23-14eeb4c72a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DT'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd830721-5d1c-4edb-9ead-4e47c1d9dacc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CM",
   "language": "python",
   "name": "cm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
