{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27f2becc-f3ca-4f4d-b8fe-d133504c8192",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8975b501-9d6f-4289-88f2-b196a9388daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "import warnings\n",
    "from functools import partial\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6b41a85-783f-4ef9-a21e-0c64a8fa1c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import Tensor\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d7d9e5-7545-4be8-8f4c-6f74b4adb275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe7a6199-f38b-4d00-8e86-713f32a84e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92e6101e-cde2-4ed7-a36c-c25cbea54d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chaosmining.data_utils import read_formulas, create_simulation_data\n",
    "from chaosmining.simulation.models import MLPRegressor\n",
    "from chaosmining.simulation.functions import abs_argmax_topk\n",
    "from chaosmining.utils import radar_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f94e9ef-b5ff-4bf1-9f32-50e871879546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, precision_score, recall_score, accuracy_score, roc_curve, auc, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcc8d87a-a388-4423-afda-5c8cfa67df9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients, Saliency, DeepLift, FeatureAblation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e054f29e-9647-4582-b03a-1ea270715390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# mpl.use('Agg')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt \n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "matplotlib.rcParams['lines.linewidth'] = 1\n",
    "matplotlib.rcParams['lines.markersize'] = 5\n",
    "plt.rcParams['figure.figsize'] = [4, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecb3965-1d2a-4ba9-90de-86b1201e0ece",
   "metadata": {},
   "source": [
    "# Santander customer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b70fe02d-9ea8-43cb-b160-e69088e910d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_train_path = '../data/house_prices_advanced_regression/train.csv'\n",
    "house_test_path = '../data/house_prices_advanced_regression/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09d5cdae-c440-4455-862a-d6fd913b5b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_train_path = '../data/santander_customer_satisfaction/train.csv'\n",
    "customer_test_path = '../data/santander_customer_satisfaction/test.csv'\n",
    "sample_path = '../data/santander_customer_satisfaction/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f911d116-6609-48c7-bf94-416b126024ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train  = pd.read_csv(customer_train_path,index_col=0)\n",
    "test   = pd.read_csv(customer_test_path, index_col=0)\n",
    "sample = pd.read_csv(sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d8c2a6f-5b39-4659-a272-7d0c7c16e097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64      259\n",
       "float64    111\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68203886-7eed-460f-a05a-d2934bc88257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc93e9a9-f7c7-458e-87fb-d07c66120e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var3                             208\n",
       "var15                            100\n",
       "ind_var1_0                         2\n",
       "ind_var1                           2\n",
       "ind_var2_0                         1\n",
       "                                ... \n",
       "num_var45_ult3                   172\n",
       "saldo_var2_ult1                    1\n",
       "saldo_medio_var13_medio_hace3      1\n",
       "saldo_medio_var13_medio_ult1       3\n",
       "TARGET                             2\n",
       "Length: 259, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select_dtypes(include=['int64']).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c98b2f9-f170-415b-8cc6-d15eb70f0fed",
   "metadata": {},
   "source": [
    "a good many of the integer features have one single value. Such columns have zero variance and thus have no predictive value, In https://www.kaggle.com/code/carlmcbrideellis/tabular-classification-with-neural-networks-keras/notebook they drop these columns from the train, as well as the test data to maintain consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8f841a-e7d8-42eb-aa26-e0ad49c8c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_to_drop = train.nunique()\n",
    "# features_to_drop = features_to_drop.loc[features_to_drop.values==1].index\n",
    "# # now drop these columns from both the training and the test datasets\n",
    "# train = train.drop(features_to_drop,axis=1)\n",
    "# test  = test.drop(features_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5702a14b-e2a2-4001-b31a-3017549a6315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64      259\n",
       "float64    111\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d88d137-ac83-4e64-89d9-6db623cae2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020, 370)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88886cbe-5e6d-4f72-b4e0-6191b75b86d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:,:-1]\n",
    "y = train['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cfeeda7-dacc-49f3-86cd-27ac922929ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99183f88-694c-41a7-9ea2-1437fc27b025",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "X_resampled = X_resampled.to_numpy()\n",
    "y_resampled = y_resampled.to_numpy().reshape(y_resampled.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9b1108e-d836-4a4a-9ada-55e10562d51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, \n",
    "                                                  train_size=0.8,\n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=42, \n",
    "                                                  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95905411-3370-42f5-8d11-b6e8391b0cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler  = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test   = scaler.transform(X_test)\n",
    "# test    = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01eb642-7e9f-4884-b33d-5d107495bdfe",
   "metadata": {},
   "source": [
    "# Training and Test a MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03b69928-b490-4257-8787-aba2ceb8c72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TensorDataset(Tensor(X_train), Tensor(y_train))\n",
    "train_loader = DataLoader(train_set, batch_size=1000, shuffle=True)\n",
    "test_set = TensorDataset(Tensor(X_test), Tensor(y_test))\n",
    "test_loader = DataLoader(test_set, batch_size=y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "069d51e4-28a0-4c9a-a284-efffb8f5ab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_sizes = (100,100,100)\n",
    "num_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c72134c-cf77-4d74-954a-5f47e48c0203",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5911ef9a-9822-4656-b389-b01523fa07ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class LinearBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_channels, out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor)-> Tensor:\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "    \n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, in_channels: int, sizes: List[int], p: float=0.0):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            LinearBlock(in_channels, sizes[0]),\n",
    "            *[LinearBlock(sizes[i], sizes[i+1]) for i in range(len(sizes)-1)]\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(sizes[-1], 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x: Tensor)-> Tensor:\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.project(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c9dfcc9-54e6-42cb-9c81-3b4cbd9e7550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(\n",
       "  (blocks): ModuleList(\n",
       "    (0): LinearBlock(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=369, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1-2): 2 x LinearBlock(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (project): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLPClassifier(X_train.shape[-1], hidden_layer_sizes, p=0.0)\n",
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f46068f1-8b8c-4aa5-88b1-7b2d4c982d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.MSELoss(reduction='mean')\n",
    "criterion = nn.BCELoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8da5584b-ee82-4ae5-b999-2a335843dead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, num_epochs, optimizer):\n",
    "    pbar = trange(num_epochs, desc='Train', unit='epoch', initial=0, disable=False)\n",
    "    for epoch in pbar:  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in dataloader:\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            # forward pass\n",
    "            outputs = model(inputs)\n",
    "            # defining loss\n",
    "            # print(outputs.dtype,targets.dtype)\n",
    "            # print(outputs.shape,targets.shape)\n",
    "            # print(outputs[0],targets[0])\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # computing gradients\n",
    "            loss.backward()\n",
    "            # accumulating running loss\n",
    "            running_loss += loss.item()\n",
    "            # updated weights based on computed gradients\n",
    "            optimizer.step()\n",
    "        pbar.set_postfix(loss = '%.3f' % running_loss)\n",
    "        # print(loss.item())\n",
    "    print('train loss:', running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cd13aea-b56a-4a19-a0d5-8328781ee487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc6fcc712994eeaba931efb3d506788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.679726392030716\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, num_epochs, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42595076-2dd5-4a86-a0bc-5f4cb50b609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(Tensor(X_test).to(device)).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30a2f6c9-d3ea-41a5-b62f-409d574b8b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test =y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d307ef1-a2c8-41a4-8302-dcc4d5de2aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test auc is 0.7670218999082438\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test,y_pred)\n",
    "print('Test auc is', auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f53a62e-c50b-4311-94bf-755be98e25ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7256071945786395"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_test,np.around(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80285ff8-b7c1-4ed0-91e3-c9d7794b400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model(Tensor(X_train[0:1]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57dfa8d7-b126-4822-a29d-ffc7da238fdb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4812, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fpr, tpr, thresholds \u001b[38;5;241m=\u001b[39m  \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain auc is\u001b[39m\u001b[38;5;124m'\u001b[39m, auc(fpr, tpr))\n",
      "File \u001b[0;32m~/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:1108\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   1007\u001b[0m     {\n\u001b[1;32m   1008\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m ):\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m \n\u001b[1;32m   1021\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;124;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1108\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:819\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[0;32m--> 819\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n\u001b[1;32m    821\u001b[0m y_score \u001b[38;5;241m=\u001b[39m column_or_1d(y_score)\n",
      "File \u001b[0;32m~/miniconda3/envs/CM/lib/python3.11/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4812, 1]"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds =  roc_curve(y_train, y_train_pred)\n",
    "print('Train auc is', auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d687d80-5386-4ce7-874d-c4f72b1ee50f",
   "metadata": {},
   "source": [
    "# Iterative Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8456b7ff-6f7b-41e4-a8a7-2cf0386e5481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe01570d-aba7-4745-8bb5-2b74a748aff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for xai_method in [Saliency,DeepLift,FeatureAblation,IntegratedGradients]:\n",
    "    print(xai_method.get_name())\n",
    "    reduce_rate = 0.8\n",
    "    best_score = 0\n",
    "    num_cur_features = X_train.shape[-1]\n",
    "    select_arr = np.ones(num_cur_features)\n",
    "    remaining_inds = np.nonzero(select_arr)[0]\n",
    "    num_select = 73\n",
    "    while num_cur_features>num_select:\n",
    "        bool_arr = np.array(select_arr, dtype='bool') \n",
    "        print(X_train[...,bool_arr].shape)\n",
    "        train_set = TensorDataset(Tensor(X_train[...,bool_arr]), Tensor(y_train))\n",
    "        train_loader = DataLoader(train_set, batch_size=y_train.shape[0], shuffle=True)\n",
    "        test_set = TensorDataset(Tensor(X_test[...,bool_arr]), Tensor(y_test))\n",
    "        test_loader = DataLoader(test_set, batch_size=y_test.shape[0])\n",
    "    \n",
    "        model = MLPClassifier(int(np.sum(select_arr)), hidden_layer_sizes, p=0.0)\n",
    "        model.to(device)\n",
    "        model.train()\n",
    "    \n",
    "        # criterion = nn.MSELoss(reduction='mean')\n",
    "        criterion = nn.BCELoss(reduction='mean')\n",
    "        optimizer = torch.optim.Adam(model.parameters(), 0.001)\n",
    "    \n",
    "        train(model, train_loader, num_epochs, optimizer)\n",
    "    \n",
    "        model.eval()\n",
    "        y_pred = model(Tensor(X_test[...,bool_arr]).to(device)).detach().cpu().numpy()\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,y_pred)\n",
    "        score = auc(fpr, tpr)\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        print('Test auc is', auc_score)\n",
    "        ACC = balanced_accuracy_score(y_test,np.around(y_pred))\n",
    "        \n",
    "        print('Test ACC is', ACC)\n",
    "    \n",
    "        xai = xai_method(model)\n",
    "        # xai = DeepLift(model)\n",
    "        # xai = FeatureAblation(model)\n",
    "        # xai = IntegratedGradients(model)\n",
    "    \n",
    "        num_remove = int(num_cur_features*(1-reduce_rate))\n",
    "        if num_cur_features - num_remove<num_select:\n",
    "            num_remove = num_cur_features - num_select\n",
    "        print('num_remove', num_remove)\n",
    "        xai_attr_test = xai.attribute(Tensor(X_test[...,bool_arr]).to(device))\n",
    "        abs_xai_attr_test = np.abs(xai_attr_test.detach().cpu().numpy()).mean(0)\n",
    "        inds = np.argpartition(abs_xai_attr_test, num_remove)[:num_remove]\n",
    "        inds_to_remove = remaining_inds[inds]\n",
    "        select_arr[inds_to_remove] = 0\n",
    "        \n",
    "        remaining_inds = np.nonzero(select_arr)[0]\n",
    "        num_cur_features -= num_remove\n",
    "        print('remaining', len(remaining_inds), num_cur_features)\n",
    "    # print('The best score is:', best_score)\n",
    "    # print('best features:', np.where(select_arr==1)[0])\n",
    "    np.save(f'./{xai_method.get_name()}_feature.npy',np.where(select_arr==1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c373b3a6-a8fe-46db-bdbe-974da1e1b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_saliency = np.load('Saliency_feature.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95542401-3cb1-43da-8c08-7ccc18ff6b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_saliency.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e7dbd-34bb-4436-82ad-114aa172d207",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_arr = np.array(select_arr, dtype='bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f315d3-f4a0-457f-a06e-0104148be04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[...,bool_arr].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f441d4-26ac-43b3-acda-3560dd558559",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5100a33-80e2-40d1-9c80-03ba39fe5a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The best score is:', best_score)\n",
    "print('best features:', np.where(select_arr==1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa2265f-bc56-47d4-9f8a-5e39abb58c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27da6586-0db1-4790-8772-21641f0ed2dd",
   "metadata": {},
   "source": [
    "# XGboost and SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664c4d6d-8b18-49e3-b9d8-c08ab056ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=500, learning_rate=0.05, random_state=156).fit(X_train, np.squeeze(y_train))\n",
    "clf.score(X_test, np.squeeze(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdba671-ea1f-40d7-a76a-cb7462beaadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test,y_pred_proba)\n",
    "print('Test auc is', auc(fpr, tpr))\n",
    "acc = balanced_accuracy_score(y_test,np.around(y_pred_proba))\n",
    "print(f'balanced accuarcy score:{acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331e51b9-55ea-4ceb-8562-9ebb834eb899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a98104-64c5-4232-805c-124a443ae61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(gamma='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604a2d44-000a-432b-bb18-29138cc0a330",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, np.squeeze(y_train))\n",
    "y_pred_proba = clf.predict(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test,y_pred_proba)\n",
    "print('Test auc is', auc(fpr, tpr))\n",
    "acc = balanced_accuracy_score(y_test,np.around(y_pred_proba))\n",
    "print(f'balanced accuarcy score:{acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89734eb0-42fd-423a-ae0a-84f742737fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa2db9a-c93a-430f-b1d7-510da59a1616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde50c13-f1e0-4007-a933-baa2176f05ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty='l1',solver='liblinear')\n",
    "clf.fit(X_train, np.squeeze(y_train))\n",
    "y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "print(y_pred_proba)\n",
    "fpr, tpr, thresholds = roc_curve(y_test,y_pred_proba)\n",
    "print('Test auc is', auc(fpr, tpr))\n",
    "acc = balanced_accuracy_score(y_test,np.around(y_pred_proba))\n",
    "print(f'balanced accuarcy score:{acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d6f25-f136-413e-a63a-f0e52401e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb8937-4949-4c11-a078-418df240bbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef[:,334]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ab466e-4a75-4596-9087-1e74cf213e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(coef!=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196a7e32-eede-499d-9102-3a0d40df24dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_coef = coef[:,np.where(coef!=0)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c190db-1526-4ef0-9c7c-361d5107a093",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_coef.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e80ad9-ddbc-413e-8ca2-a445f12c8133",
   "metadata": {},
   "source": [
    "# RFE logstic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41823ccf-5dce-4656-a05c-b1bfc6c7a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = LogisticRegression(penalty=None)\n",
    "selector = RFE(estimator, n_features_to_select=73, step=1)\n",
    "selector = selector.fit(X_train, np.squeeze(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82e97ca-883b-4c6e-bdc3-32428bf6ae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_RFE = selector.ranking_\n",
    "selected_RFE[selected_RFE != 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622dbe71-a5b0-4b85-8edc-540bd9e6b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_arr = np.array(selected_RFE, dtype='bool') \n",
    "X_train_selected = X_train[...,bool_arr]\n",
    "X_test_selected = X_test[...,bool_arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74cfed4-a9ab-430a-8518-b79dac09d61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bf3e83-1ca4-4c8d-bf7c-ee04a8a83cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty=None)\n",
    "clf.fit(X_train_selected, np.squeeze(y_train))\n",
    "\n",
    "y_pred_proba_linear = clf.predict_proba(X_test_selected)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test,y_pred_proba_linear)\n",
    "print('Test auc is', auc(fpr, tpr))\n",
    "acc = balanced_accuracy_score(y_test,np.around(y_pred_proba_linear))\n",
    "print(f'balanced accuarcy score:{acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0bfbfd-35e3-4a29-9249-84f2f3c73934",
   "metadata": {},
   "source": [
    "# RFE svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185ab525-d337-43e3-b55f-c456e0f6d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = SVC(                    \n",
    "            kernel = 'linear',\n",
    "            probability = True,\n",
    "            random_state = 42) \n",
    "selector = RFE(estimator, n_features_to_select=73, step=1)\n",
    "selector = selector.fit(X_train, np.squeeze(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98116bb8-7885-4128-8af9-22361a505b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_RFE = selector.ranking_\n",
    "selected_RFE[selected_RFE != 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92bb38c-9cee-4888-83a5-4a27dbd2fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_arr = np.array(selected_RFE, dtype='bool') \n",
    "X_train_selected = X_train[...,bool_arr]\n",
    "X_test_selected = X_test[...,bool_arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedf06a9-5513-4113-9b0f-1d9a6a18c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d31b819-3216-4db0-84a2-400a01720423",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty=None)\n",
    "clf.fit(X_train_selected, np.squeeze(y_train))\n",
    "\n",
    "y_pred_proba_linear = clf.predict_proba(X_test_selected)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test,y_pred_proba_linear)\n",
    "print('Test auc is', auc(fpr, tpr))\n",
    "acc = balanced_accuracy_score(y_test,np.around(y_pred_proba_linear))\n",
    "print(f'balanced accuarcy score:{acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af077994-4eaf-4d3d-be6d-f5516149830a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CM",
   "language": "python",
   "name": "cm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
